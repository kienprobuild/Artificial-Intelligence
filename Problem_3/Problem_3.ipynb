{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eCgpkIRDymqz",
        "outputId": "63f2eb93-053d-4e8b-ebec-6bf33475cb34"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Nyp7KmVBysf3",
        "outputId": "465485dc-974d-46d1-8235-1a7666bb2f97"
      },
      "source": [
        "! pip -q install torchtext==0.6.0\n",
        "! pip -q install pyvi \n",
        "! pip -q install https://github.com/trungtv/vi_spacy/raw/master/packages/vi_spacy_model-0.2.1/dist/vi_spacy_model-0.2.1.tar.gz\n",
        "! python -m spacy link vi_spacy_model vi_spacy_model\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 71kB 3.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.5MB 5.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 747kB 48.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 42.3MB 62kB/s \n",
            "\u001b[?25h  Building wheel for vi-spacy-model (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/vi_spacy_model -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/vi_spacy_model\n",
            "You can now load the model via spacy.load('vi_spacy_model')\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L0vhOyayybh"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nic_DWH-c4it"
      },
      "source": [
        "CD to folder containing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IAez29uUEYuH",
        "outputId": "0f3f3127-5208-4e95-b9ee-2e607d2802b9"
      },
      "source": [
        "cd/content/drive/MyDrive/bai 3"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/bai 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNMvOEOTFaWt"
      },
      "source": [
        "Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxG6li-bFXE2"
      },
      "source": [
        "import os\n",
        "import dill as pickle\n",
        "import pandas as pd\n",
        "\n",
        "def read_data(src_file, trg_file):\n",
        "    src_data = open(src_file).read().strip().split('\\n')\n",
        "\n",
        "    trg_data = open(trg_file).read().strip().split('\\n')\n",
        " \n",
        "    return src_data, trg_data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDLH-p_OE3b4"
      },
      "source": [
        "opt = {\n",
        "    'train_src_data':'./data/train.en',\n",
        "    'train_trg_data':'./data/train.vi',\n",
        "    'valid_src_data':'./data/tst2013.en',\n",
        "    'valid_trg_data':'./data/tst2013.vi',\n",
        "    'src_lang':'en',\n",
        "    'trg_lang':'en',#'vi_spacy_model',\n",
        "    'max_strlen':160,\n",
        "    'batchsize':1500,\n",
        "    'device':'cuda',\n",
        "    'd_model': 512,\n",
        "    'n_layers': 6,\n",
        "    'heads': 8,\n",
        "    'dropout': 0.1,\n",
        "    'lr':0.0001,\n",
        "    'epochs':30,\n",
        "    'printevery': 200,\n",
        "    'k':5,\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SatdxVsHc3Ex"
      },
      "source": [
        "Get data from file upload to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVoWdwdfEtMQ"
      },
      "source": [
        "train_src_data, train_trg_data = read_data(opt['train_src_data'], opt['train_trg_data'])\n",
        "valid_src_data, valid_trg_data = read_data(opt['valid_src_data'], opt['valid_trg_data'])\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP94su9LE9n7",
        "outputId": "07733fc3-1547-4d09-b238-6082a277291c"
      },
      "source": [
        "train_src_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Rachel Pike : The science behind a climate headline',\n",
              " 'In 4 minutes , atmospheric chemist Rachel Pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change , with her team -- one of thousands who contributed -- taking a risky flight over the rainforest in pursuit of data on a key molecule .',\n",
              " 'I &apos;d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .',\n",
              " 'Headlines that look like this when they have to do with climate change , and headlines that look like this when they have to do with air quality or smog .',\n",
              " 'They are both two branches of the same field of atmospheric science .',\n",
              " 'Recently the headlines looked like this when the Intergovernmental Panel on Climate Change , or IPCC , put out their report on the state of understanding of the atmospheric system .',\n",
              " 'That report was written by 620 scientists from 40 countries .',\n",
              " 'They wrote almost a thousand pages on the topic .',\n",
              " 'And all of those pages were reviewed by another 400-plus scientists and reviewers , from 113 countries .',\n",
              " 'It &apos;s a big community . It &apos;s such a big community , in fact , that our annual gathering is the largest scientific meeting in the world .',\n",
              " 'Over 15,000 scientists go to San Francisco every year for that .',\n",
              " 'And every one of those scientists is in a research group , and every research group studies a wide variety of topics .',\n",
              " 'For us at Cambridge , it &apos;s as varied as the El Niño oscillation , which affects weather and climate , to the assimilation of satellite data , to emissions from crops that produce biofuels , which is what I happen to study .',\n",
              " 'And in each one of these research areas , of which there are even more , there are PhD students , like me , and we study incredibly narrow topics , things as narrow as a few processes or a few molecules .',\n",
              " 'And one of the molecules I study is called isoprene , which is here . It &apos;s a small organic molecule . You &apos;ve probably never heard of it .',\n",
              " 'The weight of a paper clip is approximately equal to 900 zeta-illion -- 10 to the 21st -- molecules of isoprene .',\n",
              " 'But despite its very small weight , enough of it is emitted into the atmosphere every year to equal the weight of all the people on the planet .',\n",
              " 'It &apos;s a huge amount of stuff . It &apos;s equal to the weight of methane .',\n",
              " 'And because it &apos;s so much stuff , it &apos;s really important for the atmospheric system .',\n",
              " 'Because it &apos;s important to the atmospheric system , we go to all lengths to study this thing .',\n",
              " 'We blow it up and look at the pieces .',\n",
              " 'This is the EUPHORE Smog Chamber in Spain .',\n",
              " 'Atmospheric explosions , or full combustion , takes about 15,000 times longer than what happens in your car .',\n",
              " 'But still , we look at the pieces .',\n",
              " 'We run enormous models on supercomputers ; this is what I happen to do .',\n",
              " 'Our models have hundreds of thousands of grid boxes calculating hundreds of variables each , on minute timescales .',\n",
              " 'And it takes weeks to perform our integrations .',\n",
              " 'And we perform dozens of integrations in order to understand what &apos;s happening .',\n",
              " 'We also fly all over the world looking for this thing .',\n",
              " 'I recently joined a field campaign in Malaysia . There are others .',\n",
              " 'We found a global atmospheric watchtower there , in the middle of the rainforest , and hung hundreds of thousands of dollars worth of scientific equipment off this tower , to look for isoprene , and of course , other things while we were there .',\n",
              " 'This is the tower in the middle of the rainforest , from above .',\n",
              " 'And this is the tower from below .',\n",
              " 'And on part of that field campaign we even brought an aircraft with us .',\n",
              " 'And this plane , the model , BA146 , which was run by FAAM , normally flies 120 to 130 people .',\n",
              " 'So maybe you took a similar aircraft to get here today .',\n",
              " 'But we didn &apos;t just fly it . We were flying at 100 meters above the top of the canopy to measure this molecule -- incredibly dangerous stuff .',\n",
              " 'We have to fly at a special incline in order to make the measurements .',\n",
              " 'We hire military and test pilots to do the maneuvering .',\n",
              " 'We have to get special flight clearance .',\n",
              " 'And as you come around the banks in these valleys , the forces can get up to two Gs .',\n",
              " 'And the scientists have to be completely harnessed in in order to make measurements while they &apos;re on board .',\n",
              " 'So , as you can imagine , the inside of this aircraft doesn &apos;t look like any plane you would take on vacation .',\n",
              " 'It &apos;s a flying laboratory that we took to make measurements in the region of this molecule .',\n",
              " 'We do all of this to understand the chemistry of one molecule .',\n",
              " 'And when one student like me has some sort of inclination or understanding about that molecule , they write one scientific paper on the subject .',\n",
              " 'And out of that field campaign we &apos;ll probably get a few dozen papers on a few dozen processes or molecules .',\n",
              " 'And as a body of knowledge builds up , it will form one subsection , or one sub-subsection of an assessment like the IPCC , although we have others .',\n",
              " 'And each one of the 11 chapters of the IPCC has six to ten subsections .',\n",
              " 'So you can imagine the scale of the effort .',\n",
              " 'In each one of those assessments that we write , we always tag on a summary , and the summary is written for a non-scientific audience .',\n",
              " 'And we hand that summary to journalists and policy makers , in order to make headlines like these .',\n",
              " 'Thank you very much .',\n",
              " 'Christopher deCharms : A look inside the brain in real time',\n",
              " 'Neuroscientist and inventor Christopher deCharms demonstrates a new way to use fMRI to show brain activity -- thoughts , emotions , pain -- while it is happening . In other words , you can actually see how you feel .',\n",
              " 'Hi . I &apos;m going to ask you to raise your arms and wave back , just the way I am -- kind of a royal wave .',\n",
              " 'You can mimic what you can see .',\n",
              " 'You can program the hundreds of muscles in your arm .',\n",
              " 'Soon , you &apos;ll be able to look inside your brain and program , control the hundreds of brain areas that you see there .',\n",
              " 'I &apos;m going to tell you about that technology .',\n",
              " 'People have wanted to look inside the human mind , the human brain , for thousands of years .',\n",
              " 'Well , coming out of the research labs just now , for our generation , is the possibility to do that .',\n",
              " 'People envision this as being very difficult .',\n",
              " 'You had to take a spaceship , shrink it down , inject it into the bloodstream .',\n",
              " 'It was terribly dangerous .',\n",
              " 'You could be attacked by white blood cells in the arteries .',\n",
              " 'But now , we have a real technology to do this .',\n",
              " 'We &apos;re going to fly into my colleague Peter &apos;s brain .',\n",
              " 'We &apos;re going to do it non-invasively using MRI .',\n",
              " 'We don &apos;t have to inject anything . We don &apos;t need radiation .',\n",
              " 'We will be able to fly into the anatomy of Peter &apos;s brain -- literally , fly into his body -- but more importantly , we can look into his mind .',\n",
              " 'When Peter moves his arm , that yellow spot you see there is the interface to the functioning of Peter &apos;s mind taking place .',\n",
              " 'Now you &apos;ve seen before that with electrodes you can control robotic arms , that brain imaging and scanners can show you the insides of brains .',\n",
              " 'What &apos;s new is that that process has typically taken days or months of analysis .',\n",
              " 'We &apos;ve collapsed that through technology to milliseconds , and that allows us to let Peter to look at his brain in real time as he &apos;s inside the scanner .',\n",
              " 'He can look at these 65,000 points of activation per second .',\n",
              " 'If he can see this pattern in his own brain , he can learn how to control it .',\n",
              " 'There have been three ways to try to impact the brain : the therapist &apos;s couch , pills and the knife .',\n",
              " 'This is a fourth alternative that you are soon going to have .',\n",
              " 'We all know that as we form thoughts , they form deep channels in our minds and in our brains .',\n",
              " 'Chronic pain is an example . If you burn yourself , you pull your hand away .',\n",
              " 'But if you &apos;re still in pain in six months &apos; or six years &apos; time , it &apos;s because these circuits are producing pain that &apos;s no longer helping you .',\n",
              " 'If we can look at the activation in the brain that &apos;s producing the pain , we can form 3D models and watch in real time the brain process information , and then we can select the areas that produce the pain .',\n",
              " 'So put your arms back up and flex your bicep .',\n",
              " 'Now imagine that you will soon be able to look inside your brain and select brain areas to do that same thing .',\n",
              " 'What you &apos;re seeing here is , we &apos;ve selected the pathways in the brain of a chronic pain patient .',\n",
              " 'This may shock you , but we &apos;re literally reading this person &apos;s brain in real time .',\n",
              " 'They &apos;re watching their own brain activation , and they &apos;re controlling the pathway that produces their pain .',\n",
              " 'They &apos;re learning to flex this system that releases their own endogenous opiates .',\n",
              " 'As they do it , in the upper left is a display that &apos;s yoked to their brain activation of their own pain being controlled .',\n",
              " 'When they control their brain , they can control their pain .',\n",
              " 'This is an investigational technology , but , in clinical trials , we &apos;re seeing a 44 to 64 percent decrease in chronic pain patients .',\n",
              " 'This is not &quot; The Matrix . &quot; You can only do this to yourself . You take control .',\n",
              " 'I &apos;ve seen inside my brain . You will too , soon .',\n",
              " 'When you do , what do you want to control ?',\n",
              " 'You will be able to look at all the aspects that make you yourself , all your experiences .',\n",
              " 'These are some of the areas we &apos;re working on today that I don &apos;t have time to go into in detail .',\n",
              " 'But I want to leave with you the big question .',\n",
              " 'We are the first generation that &apos;s going to be able to enter into , using this technology , the human mind and brain .',\n",
              " 'Where will we take it ?',\n",
              " 'Beeban Kidron : The shared wonder of film',\n",
              " 'Movies have the power to create a shared narrative experience and to shape memories and worldviews . British film director Beeban Kidron invokes iconic film scenes -- from &amp; lt ; em &amp; gt ; Miracle in Milan &amp; lt ; / em &amp; gt ; to &amp; lt ; em &amp; gt ; Boyz n the Hood &amp; lt ; / em &amp; gt ; -- as she shows how her group FILMCLUB shares great films with kids .',\n",
              " 'Evidence suggests that humans in all ages and from all cultures create their identity in some kind of narrative form .',\n",
              " 'From mother to daughter , preacher to congregant , teacher to pupil , storyteller to audience .',\n",
              " 'Whether in cave paintings or the latest uses of the Internet , human beings have always told their histories and truths through parable and fable .',\n",
              " 'We are inveterate storytellers .',\n",
              " 'But where , in our increasingly secular and fragmented world , do we offer communality of experience , unmediated by our own furious consumerism ?',\n",
              " 'And what narrative , what history , what identity , what moral code are we imparting to our young ?',\n",
              " 'Cinema is arguably the 20th century &apos;s most influential art form .',\n",
              " 'Its artists told stories across national boundaries , in as many languages , genres and philosophies as one can imagine .',\n",
              " 'Indeed , it is hard to find a subject that film has yet to tackle .',\n",
              " 'During the last decade we &apos;ve seen a vast integration of global media , now dominated by a culture of the Hollywood blockbuster .',\n",
              " 'We are increasingly offered a diet in which sensation , not story , is king .',\n",
              " 'What was common to us all 40 years ago -- the telling of stories between generations -- is now rarified .',\n",
              " 'As a filmmaker , it worried me .',\n",
              " 'As a human being , it puts the fear of God in me .',\n",
              " 'What future could the young build with so little grasp of where they &apos;ve come from and so few narratives of what &apos;s possible ?',\n",
              " 'The irony is palpable ; technical access has never been greater , cultural access never weaker .',\n",
              " 'And so in 2006 we set up FILMCLUB , an organization that ran weekly film screenings in schools followed by discussions .',\n",
              " 'If we could raid the annals of 100 years of film , maybe we could build a narrative that would deliver meaning to the fragmented and restless world of the young .',\n",
              " 'Given the access to technology , even a school in a tiny rural hamlet could project a DVD onto a white board .',\n",
              " 'In the first nine months we ran 25 clubs across the U.K. , with kids in age groups between five and 18 watching a film uninterrupted for 90 minutes .',\n",
              " 'The films were curated and contextualized .',\n",
              " 'But the choice was theirs , and our audience quickly grew to choose the richest and most varied diet that we could provide .',\n",
              " 'The outcome , immediate .',\n",
              " 'It was an education of the most profound and transformative kind .',\n",
              " 'In groups as large as 150 and as small as three , these young people discovered new places , new thoughts , new perspectives .',\n",
              " 'By the time the pilot had finished , we had the names of a thousand schools that wished to join .',\n",
              " 'The film that changed my life is a 1951 film by Vittorio De Sica , &quot; Miracle in Milan . &quot;',\n",
              " 'It &apos;s a remarkable comment on slums , poverty and aspiration .',\n",
              " 'I had seen the film on the occasion of my father &apos;s 50th birthday .',\n",
              " 'Technology then meant we had to hire a viewing cinema , find and pay for the print and the projectionist .',\n",
              " 'But for my father , the emotional and artistic importance of De Sica &apos;s vision was so great that he chose to celebrate his half-century with his three teenage children and 30 of their friends , &quot; In order , &quot; he said , &quot; to pass the baton of concern and hope on to the next generation . &quot;',\n",
              " 'In the last shot of &quot; Miracle in Milan , &quot; slum-dwellers float skyward on flying brooms .',\n",
              " 'Sixty years after the film was made and 30 years after I first saw it , I see young faces tilt up in awe , their incredulity matching mine .',\n",
              " 'And the speed with which they associate it with &quot; Slumdog Millionaire &quot; or the favelas in Rio speaks to the enduring nature .',\n",
              " 'In a FILMCLUB season about democracy and government , we screened &quot; Mr. Smith Goes to Washington . &quot;',\n",
              " 'Made in 1939 , the film is older than most of our members &apos; grandparents .',\n",
              " 'Frank Capra &apos;s classic values independence and propriety .',\n",
              " 'It shows how to do right , how to be heroically awkward .',\n",
              " 'It is also an expression of faith in the political machine as a force of honor .',\n",
              " 'Shortly after &quot; Mr. Smith &quot; became a FILMCLUB classic , there was a week of all-night filibustering in the House of Lords .',\n",
              " 'And it was with great delight that we found young people up and down the country explaining with authority what filibustering was and why the Lords might defy their bedtime on a point of principle .',\n",
              " 'After all , Jimmy Stewart filibustered for two entire reels .',\n",
              " 'In choosing &quot; Hotel Rwanda , &quot; they explored genocide of the most brutal kind .',\n",
              " 'It provoked tears as well as incisive questions about unarmed peace-keeping forces and the double-dealing of a Western society that picks its moral fights with commodities in mind .',\n",
              " 'And when &quot; Schindler &apos;s List &quot; demanded that they never forget , one child , full of the pain of consciousness , remarked , &quot; We already forgot , otherwise how did &apos; Hotel Rwanda &apos; happen ? &quot;',\n",
              " 'As they watch more films their lives got palpably richer .',\n",
              " '&quot; Pickpocket &quot; started a debate about criminality disenfranchisement .',\n",
              " '&quot; To Sir , with Love &quot; ignited its teen audience .',\n",
              " 'They celebrated a change in attitude towards non-white Britons , but railed against our restless school system that does not value collective identity , unlike that offered by Sidney Poitier &apos;s careful tutelage .',\n",
              " 'By now , these thoughtful , opinionated , curious young people thought nothing of tackling films of all forms -- black and white , subtitled , documentary , non-narrative , fantasy -- and thought nothing of writing detailed reviews that competed to favor one film over another in passionate and increasingly sophisticated prose .',\n",
              " 'Six thousand reviews each school week vying for the honor of being review of the week .',\n",
              " 'From 25 clubs , we became hundreds , then thousands , until we were nearly a quarter of a million kids in 7,000 clubs right across the country .',\n",
              " 'And although the numbers were , and continue to be , extraordinary , what became more extraordinary was how the experience of critical and curious questioning translated into life .',\n",
              " 'Some of our kids started talking with their parents , others with their teachers , or with their friends .',\n",
              " 'And those without friends started making them .',\n",
              " 'The films provided communality across all manner of divide .',\n",
              " 'And the stories they held provided a shared experience .',\n",
              " '&quot; Persepolis &quot; brought a daughter closer to her Iranian mother , and &quot; Jaws &quot; became the way in which one young boy was able to articulate the fear he &apos;d experienced in flight from violence that killed first his father then his mother , the latter thrown overboard on a boat journey .',\n",
              " 'Who was right , who wrong ?',\n",
              " 'What would they do under the same conditions ?',\n",
              " 'Was the tale told well ?',\n",
              " 'Was there a hidden message ?',\n",
              " 'How has the world changed ? How could it be different ?',\n",
              " 'A tsunami of questions flew out of the mouths of children who the world didn &apos;t think were interested .',\n",
              " 'And they themselves had not known they cared .',\n",
              " 'And as they wrote and debated , rather than seeing the films as artifacts , they began to see themselves .',\n",
              " 'I have an aunt who is a wonderful storyteller .',\n",
              " 'In a moment she can invoke images of running barefoot on Table Mountain and playing cops and robbers .',\n",
              " 'Quite recently she told me that in 1948 , two of her sisters and my father traveled on a boat to Israel without my grandparents .',\n",
              " 'When the sailors mutinied at sea in a demand for humane conditions , it was these teenagers that fed the crew .',\n",
              " 'I was past 40 when my father died .',\n",
              " 'He never mentioned that journey .',\n",
              " 'My mother &apos;s mother left Europe in a hurry without her husband , but with her three-year-old daughter and diamonds sewn into the hem of her skirt .',\n",
              " 'After two years in hiding , my grandfather appeared in London .',\n",
              " 'He was never right again .',\n",
              " 'And his story was hushed as he assimilated .',\n",
              " 'My story started in England with a clean slate and the silence of immigrant parents .',\n",
              " 'I had &quot; Anne Frank , &quot; &quot; The Great Escape , &quot; &quot; Shoah , &quot; &quot; Triumph of the Will . &quot;',\n",
              " 'It was Leni Riefenstahl in her elegant Nazi propaganda who gave context to what the family had to endure .',\n",
              " 'These films held what was too hurtful to say out loud , and they became more useful to me than the whispers of survivors and the occasional glimpse of a tattoo on a maiden aunt &apos;s wrist .',\n",
              " 'Purists may feel that fiction dissipates the quest of real human understanding , that film is too crude to tell a complex and detailed history , or that filmmakers always serve drama over truth .',\n",
              " 'But within the reels lie purpose and meaning .',\n",
              " 'As one 12-year-old said after watching &quot; Wizard of Oz , &quot; &quot; Every person should watch this , because unless you do you may not know that you too have a heart . &quot;',\n",
              " 'We honor reading , why not honor watching with the same passion ?',\n",
              " 'Consider &quot; Citizen Kane &quot; as valuable as Jane Austen .',\n",
              " 'Agree that &quot; Boyz n the Hood , &quot; like Tennyson , offers an emotional landscape and a heightened understanding that work together .',\n",
              " 'Each a piece of memorable art , each a brick in the wall of who we are .',\n",
              " 'And it &apos;s okay if we remember Tom Hanks better than astronaut Jim Lovell or have Ben Kingsley &apos;s face superimposed onto that of Gandhi &apos;s .',\n",
              " 'And though not real , Eve Harrington , Howard Beale , Mildred Pierce are an opportunity to discover what it is to be human , and no less helpful to understanding our life and times as Shakespeare is in illuminating the world of Elizabethan England .',\n",
              " 'We guessed that film , whose stories are a meeting place of drama , music , literature and human experience , would engage and inspire the young people participating in FILMCLUB .',\n",
              " 'What we could not have foreseen was the measurable improvements in behavior , confidence and academic achievement .',\n",
              " 'Once-reluctant students now race to school , talk to their teachers , fight , not on the playground , but to choose next week &apos;s film -- young people who have found self-definition , ambition and an appetite for education and social engagement from the stories they have witnessed .',\n",
              " 'Our members defy the binary description of how we so often describe our young .',\n",
              " 'They are neither feral nor myopically self-absorbed .',\n",
              " 'They are , like other young people , negotiating a world with infinite choice , but little culture of how to find meaningful experience .',\n",
              " 'We appeared surprised at the behaviors of those who define themselves by the size of the tick on their shoes , yet acquisition has been the narrative we have offered .',\n",
              " 'If we want different values we have to tell a different story , a story that understands that an individual narrative is an essential component of a person &apos;s identity , that a collective narrative is an essential component of a cultural identity , and without it it is impossible to imagine yourself as part of a group .',\n",
              " 'Because when these people get home after a screening of &quot; Rear Window &quot; and raise their gaze to the building next door , they have the tools to wonder who , apart from them , is out there and what is their story .',\n",
              " 'Thank you .',\n",
              " 'Ellen Jorgensen : Biohacking -- you can do it , too',\n",
              " 'We have personal computing , why not personal biotech ? That &apos;s the question biologist Ellen Jorgensen and her colleagues asked themselves before opening Genspace , a nonprofit DIYbio lab in Brooklyn devoted to citizen science , where amateurs can go and tinker with biotechnology . Far from being a sinister Frankenstein &apos;s lab , Genspace offers a long list of fun , creative and practical uses for DIYbio .',\n",
              " 'It &apos;s a great time to be a molecular biologist .',\n",
              " 'Reading and writing DNA code is getting easier and cheaper .',\n",
              " 'By the end of this year , we &apos;ll be able to sequence the three million bits of information in your genome in less than a day and for less than 1,000 euros .',\n",
              " 'Biotech is probably the most powerful and the fastest-growing technology sector .',\n",
              " 'It has the power , potentially , to replace our fossil fuels , to revolutionize medicine , and to touch every aspect of our daily lives .',\n",
              " 'So who gets to do it ?',\n",
              " 'I think we &apos;d all be pretty comfortable with this guy doing it .',\n",
              " 'But what about that guy ?',\n",
              " 'In 2009 , I first heard about DIYbio .',\n",
              " 'It &apos;s a movement that -- it advocates making biotechnology accessible to everyone , not just scientists and people in government labs .',\n",
              " 'The idea is that if you open up the science and you allow diverse groups to participate , it could really stimulate innovation .',\n",
              " 'Putting technology in the hands of the end user is usually a good idea because they &apos;ve got the best idea of what their needs are .',\n",
              " 'And here &apos;s this really sophisticated technology coming down the road , all these associated social , moral , ethical questions , and we scientists are just lousy at explaining to the public just exactly what it is we &apos;re doing in those labs .',\n",
              " 'So wouldn &apos;t it be nice if there was a place in your local neighborhood where you could go and learn about this stuff , do it hands-on ?',\n",
              " 'I thought so .',\n",
              " 'So , three years ago , I got together with some friends of mine who had similar aspirations and we founded Genspace .',\n",
              " 'It &apos;s a nonprofit , a community biotech lab in Brooklyn , New York , and the idea was people could come , they could take classes and putter around in the lab in a very open , friendly atmosphere .',\n",
              " 'None of my previous experience prepared me for what came next . Can you guess ?',\n",
              " 'The press started calling us .',\n",
              " 'And the more we talked about how great it was to increase science literacy , the more they wanted to talk about us creating the next Frankenstein , and as a result , for the next six months , when you Googled my name , instead of getting my scientific papers , you got this .',\n",
              " '&#91; &quot; Am I a biohazard ? &quot; &#93; It was pretty depressing .',\n",
              " 'The only thing that got us through that period was that we knew that all over the world , there were other people that were trying to do the same thing that we were .',\n",
              " 'They were opening biohacker spaces , and some of them were facing much greater challenges than we did , more regulations , less resources .',\n",
              " 'But now , three years later , here &apos;s where we stand .',\n",
              " 'It &apos;s a vibrant , global community of hackerspaces , and this is just the beginning .',\n",
              " 'These are some of the biggest ones , and there are others opening every day .',\n",
              " 'There &apos;s one probably going to open up in Moscow , one in South Korea , and the cool thing is they each have their own individual flavor that grew out of the community they came out of .',\n",
              " 'Let me take you on a little tour .',\n",
              " 'Biohackers work alone .',\n",
              " 'We work in groups , in big cities — — and in small villages .',\n",
              " 'We reverse engineer lab equipment .',\n",
              " 'We genetically engineer bacteria .',\n",
              " 'We hack hardware , software , wetware , and , of course , the code of life .',\n",
              " 'We like to build things .',\n",
              " 'Then we like to take things apart .',\n",
              " 'We make things grow .',\n",
              " 'We make things glow .',\n",
              " 'And we make cells dance .',\n",
              " 'The spirit of these labs , it &apos;s open , it &apos;s positive , but , you know , sometimes when people think of us , the first thing that comes to mind is bio-safety , bio-security , all the dark side stuff .',\n",
              " 'I &apos;m not going to minimize those concerns .',\n",
              " 'Any powerful technology is inherently dual use , and , you know , you get something like synthetic biology , nanobiotechnology , it really compels you , you have to look at both the amateur groups but also the professional groups , because they have better infrastructure , they have better facilities , and they have access to pathogens .',\n",
              " 'So the United Nations did just that , and they recently issued a report on this whole area , and what they concluded was the power of this technology for positive was much greater than the risk for negative , and they even looked specifically at the DIYbio community , and they noted , not surprisingly , that the press had a tendency to consistently overestimate our capabilities and underestimate our ethics .',\n",
              " 'As a matter of fact , DIY people from all over the world , America , Europe , got together last year , and we hammered out a common code of ethics .',\n",
              " 'That &apos;s a lot more than conventional science has done .',\n",
              " 'Now , we follow state and local regulations .',\n",
              " 'We dispose of our waste properly , we follow safety procedures , we don &apos;t work with pathogens .',\n",
              " 'You know , if you &apos;re working with a pathogen , you &apos;re not part of the biohacker community , you &apos;re part of the bioterrorist community , I &apos;m sorry .',\n",
              " 'And sometimes people ask me , &quot; Well , what about an accident ? &quot;',\n",
              " 'Well , working with the safe organisms that we normally work with , the chance of an accident happening with somebody accidentally creating , like , some sort of superbug , that &apos;s literally about as probable as a snowstorm in the middle of the Sahara Desert .',\n",
              " 'Now , it could happen , but I &apos;m not going to plan my life around it .',\n",
              " 'I &apos;ve actually chosen to take a different kind of risk .',\n",
              " 'I signed up for something called the Personal Genome Project .',\n",
              " 'It &apos;s a study at Harvard where , at the end of the study , they &apos;re going to take my entire genomic sequence , all of my medical information , and my identity , and they &apos;re going to post it online for everyone to see .',\n",
              " 'There were a lot of risks involved that they talked about during the informed consent portion .',\n",
              " 'The one I liked the best is , someone could download my sequence , go back to the lab , synthesize some fake Ellen DNA , and plant it at a crime scene .',\n",
              " 'But like DIYbio , the positive outcomes and the potential for good for a study like that far outweighs the risk .',\n",
              " 'Now , you might be asking yourself , &quot; Well , you know , what would I do in a biolab ? &quot;',\n",
              " 'Well , it wasn &apos;t that long ago we were asking , &quot; Well , what would anyone do with a personal computer ? &quot;',\n",
              " 'So this stuff is just beginning .',\n",
              " 'We &apos;re only seeing just the tip of the DNA iceberg .',\n",
              " 'Let me show you what you could do right now .',\n",
              " 'A biohacker in Germany , a journalist , wanted to know whose dog was leaving little presents on his street ?',\n",
              " 'Yep , you guessed it . He threw tennis balls to all the neighborhood dogs , analyzed the saliva , identified the dog , and confronted the dog owner .',\n",
              " 'I discovered an invasive species in my own backyard .',\n",
              " 'Looked like a ladybug , right ?',\n",
              " 'It actually is a Japanese beetle .',\n",
              " 'And the same kind of technology -- it &apos;s called DNA barcoding , it &apos;s really cool -- You can use it to check if your caviar is really beluga , if that sushi is really tuna , or if that goat cheese that you paid so much for is really goat &apos;s .',\n",
              " 'In a biohacker space , you can analyze your genome for mutations .',\n",
              " 'You can analyze your breakfast cereal for GMO &apos;s , and you can explore your ancestry .',\n",
              " 'You can send weather balloons up into the stratosphere , collect microbes , see what &apos;s up there .',\n",
              " 'You can make a biocensor out of yeast to detect pollutants in water .',\n",
              " 'You can make some sort of a biofuel cell .',\n",
              " 'You can do a lot of things .',\n",
              " 'You can also do an art science project . Some of these are really spectacular , and they look at social , ecological problems from a completely different perspective .',\n",
              " 'It &apos;s really cool .',\n",
              " 'Some people ask me , well , why am I involved ?',\n",
              " 'I could have a perfectly good career in mainstream science .',\n",
              " 'The thing is , there &apos;s something in these labs that they have to offer society that you can &apos;t find anywhere else .',\n",
              " 'There &apos;s something sacred about a space where you can work on a project , and you don &apos;t have to justify to anyone that it &apos;s going to make a lot of money , that it &apos;s going to save mankind , or even that it &apos;s feasible .',\n",
              " 'It just has to follow safety guidelines .',\n",
              " 'If you had spaces like this all over the world , it could really change the perception of who &apos;s allowed to do biotech .',\n",
              " 'It &apos;s spaces like these that spawned personal computing .',\n",
              " 'Why not personal biotech ?',\n",
              " 'If everyone in this room got involved , who knows what we could do ?',\n",
              " 'This is such a new area , and as we say back in Brooklyn , you ain &apos;t seen nothin &apos; yet .',\n",
              " 'Geert Chatrou : A whistleblower you haven &apos;t heard',\n",
              " 'In this engaging talk , world champion whistler Geert Chatrou performs the whimsical &quot; Eleonora &quot; by A. Honhoff , and his own &quot; Fête de la Belle . &quot; In a fascinating interlude , he talks about what brought him to the craft . &amp; lt ; em &amp; gt ; &amp; lt ; / em &amp; gt ;',\n",
              " 'Thank you very much .',\n",
              " 'That was whistling .',\n",
              " 'I &apos;m trying to do this in English .',\n",
              " 'What is a chubby , curly-haired guy from Holland -- why is he whistling ?',\n",
              " 'Well actually , I &apos;ve &#91; been &#93; whistling since the age of four , about four .',\n",
              " 'My dad was always whistling around the house , and I just thought that &apos;s part of communication in my family .',\n",
              " 'So I whistled along with him .',\n",
              " 'And actually , till I was 34 , I always annoyed and irritated people with whistling , because , to be honest , my whistling is a kind of deviant behavior .',\n",
              " 'I whistled alone . I whistled in the classroom .',\n",
              " 'I whistled on &#91; my &#93; bike . I whistled everywhere .',\n",
              " 'And I also whistled at a Christmas Eve party with my family-in-law .',\n",
              " 'And they had some , in my opinion , terrible Christmas music .',\n",
              " 'And when I hear music that I don &apos;t like , I try to make it better .',\n",
              " 'So &quot; Rudolph the Red-Nosed Reindeer &quot; -- you know it ?',\n",
              " 'But it can also sound like this .',\n",
              " 'But during a Christmas party -- at dinner actually -- it &apos;s very annoying .',\n",
              " 'So my sister-in-law asked me a few times , &quot; Please stop whistling . &quot;',\n",
              " 'And I just couldn &apos;t .',\n",
              " 'And at one point -- and I had some wine , I have to admit that -- at one point I said , &quot; If there was a contest , I would join . &quot;',\n",
              " 'And two weeks later I received a text message : &quot; You &apos;re going to America . &quot;',\n",
              " 'So , okay , I &apos;m going to America .',\n",
              " 'I would love to , but why ?',\n",
              " 'So I immediately called her up , of course .',\n",
              " 'She Googled , and she found this World Whistling Championship in America , of course .',\n",
              " 'She didn &apos;t expect me to go there .',\n",
              " 'And I would have lost my face .',\n",
              " 'I don &apos;t know if that &apos;s correct English .',\n",
              " 'But the Dutch people here will understand what I mean .',\n",
              " 'I lost my face .',\n",
              " 'And she thought , &quot; He will never go there . &quot;',\n",
              " 'But actually I did .',\n",
              " 'So I went to Louisburg , North Carolina , southeast United States , and I entered the world of whistling .',\n",
              " 'And I also entered the world championship , and I won there in 2004 .',\n",
              " 'That was great fun , of course .',\n",
              " 'And to defend my title -- like judokas do and sportsmen -- I thought , well let &apos;s go back in 2005 , and I won again .',\n",
              " 'Then I couldn &apos;t participate for a few years .',\n",
              " 'And in 2008 I entered again in Japan , Tokyo , and I won again .',\n",
              " 'So what happened now is I &apos;m standing here in Rotterdam , in the beautiful city , on a big stage , and I &apos;m talking about whistling .',\n",
              " 'And actually I earn my money whistling at the moment .',\n",
              " 'So I quit my day job as a nurse .',\n",
              " 'And I try to live my dream -- well , actually , it was never my dream , but it sounds so good .',\n",
              " 'Okay , I &apos;m not the only one whistling here .',\n",
              " 'You say , &quot; Huh , what do you mean ? &quot;',\n",
              " 'Well actually , you are going to whistle along .',\n",
              " 'And then always the same thing happens : people are watching each other and think , &quot; Oh , my God .',\n",
              " 'Why ? Can I go away ? &quot;',\n",
              " 'No , you can &apos;t .',\n",
              " 'Actually it &apos;s very simple .',\n",
              " 'The track that I will whistle is called &quot; Fête de la Belle . &quot;',\n",
              " 'It &apos;s about 80 minutes long .',\n",
              " 'No , no , no . It &apos;s four minutes long .',\n",
              " 'And I want to first rehearse with you your whistling .',\n",
              " 'So I whistle the tone .',\n",
              " 'Sorry . I forgot one thing .',\n",
              " 'You whistle the same tone as me .',\n",
              " 'I heard a wide variety of tones .',\n",
              " 'This is very promising .',\n",
              " 'This is very promising .',\n",
              " 'I &apos;ll ask the technicians to start the music .',\n",
              " 'And if it &apos;s started , I just point where you whistle along , and we will see what happens .',\n",
              " 'Oh , hah .',\n",
              " 'I &apos;m so sorry , technicians .',\n",
              " 'I &apos;m so used to that .',\n",
              " 'I start it myself .',\n",
              " 'Okay , here it is .',\n",
              " 'Okay .',\n",
              " 'It &apos;s easy , isn &apos;t it ?',\n",
              " 'Now comes the solo . I propose I do that myself .',\n",
              " 'Max Westerman : Geert Chatrou , the World Champion &#91; of &#93; Whistling .',\n",
              " 'Geert Chatrou : Thank you . Thank you .',\n",
              " 'Roberto D &apos;Angelo + Francesca Fedeli : In our baby &apos;s illness , a life lesson',\n",
              " 'Roberto D &apos;Angelo and Francesca Fedeli thought their baby boy Mario was healthy -- until at 10 days old , they discovered he &apos;d had a perinatal stroke . With Mario unable to control the left side of his body , they grappled with tough questions : Would he be &quot; normal ? &quot; Could he live a full life ? The poignant story of parents facing their fears -- and how they turned them around .',\n",
              " 'Francesca Fedeli : Ciao .',\n",
              " 'So he &apos;s Mario . He &apos;s our son .',\n",
              " 'He was born two and a half years ago , and I had a pretty tough pregnancy because I had to stay still in a bed for , like , eight months .',\n",
              " 'But in the end everything seemed to be under control .',\n",
              " 'So he got the right weight at birth .',\n",
              " 'He got the right Apgar index .',\n",
              " 'So we were pretty reassured by this .',\n",
              " 'But at the end , 10 days later after he was born , we discovered that he had a stroke .',\n",
              " 'As you might know , a stroke is a brain injury .',\n",
              " 'A perinatal stroke could be something that can happen during the nine months of pregnancy or just suddenly after the birth , and in his case , as you can see , the right part of his brain has gone .',\n",
              " 'So the effect that this stroke could have on Mario &apos;s body could be the fact that he couldn &apos;t be able to control the left side of his body .',\n",
              " 'Just imagine , if you have a computer and a printer and you want to transmit , to input to print out a document , but the printer doesn &apos;t have the right drives , so the same is for Mario .',\n",
              " 'It &apos;s just like , he would like to move his left side of his body , but he &apos;s not able to transmit the right input to move his left arm and left leg .',\n",
              " 'So life had to change .',\n",
              " 'We needed to change our schedule .',\n",
              " 'We needed to change the impact that this birth had on our life .',\n",
              " 'As you may imagine , unfortunately , we were not ready .',\n",
              " 'Nobody taught us how to deal with such kinds of disabilities , and as many questions as possible started to come to our minds .',\n",
              " 'And that has been really a tough time .',\n",
              " 'Questions , some basics , like , you know , why did this happen to us ?',\n",
              " 'And what went wrong ?',\n",
              " 'Some more tough , like , really , what will be the impact on Mario &apos;s life ?',\n",
              " 'I mean , at the end , will he be able to work ?',\n",
              " 'Will he be able to be normal ?',\n",
              " 'And , you know , as a parent , especially for the first time , why is he not going to be better than us ?',\n",
              " 'And this , indeed , really is tough to say , but a few months later , we realized that we were really feeling like a failure .',\n",
              " 'I mean , the only real product of our life , at the end , was a failure .',\n",
              " 'And you know , it was not a failure for ourselves in itself , but it was a failure that will impact his full life .',\n",
              " 'Honestly , we went down .',\n",
              " 'I mean we went really down , but at the end , we started to look at him , and we said , we have to react .',\n",
              " 'So immediately , as Francesca said , we changed our life .',\n",
              " 'We started physiotherapy , we started the rehabilitation , and one of the paths that we were following in terms of rehabilitation is the mirror neurons pilot .',\n",
              " 'Basically , we spent months doing this with Mario .',\n",
              " 'You have an object , and we showed him how to grab the object .',\n",
              " 'Now , the theory of mirror neurons simply says that in your brains , exactly now , as you watch me doing this , you are activating exactly the same neurons as if you do the actions .',\n",
              " 'It looks like this is the leading edge in terms of rehabilitation .',\n",
              " 'But one day we found that Mario was not looking at our hand .',\n",
              " 'He was looking at us .',\n",
              " 'We were his mirror .',\n",
              " 'And the problem , as you might feel , is that we were down , we were depressed , we were looking at him as a problem , not as a son , not from a positive perspective .',\n",
              " 'And that day really changed our perspective .',\n",
              " 'We realized that we had to become a better mirror for Mario .',\n",
              " 'We restarted from our strengths , and at the same time we restarted from his strengths .',\n",
              " 'We stopped looking at him as a problem , and we started to look at him as an opportunity to improve .',\n",
              " 'And really , this was the change , and from our side , we said , &quot; What are our strengths that we really can bring to Mario ? &quot;',\n",
              " 'And we started from our passions .',\n",
              " 'I mean , at the end , my wife and myself are quite different , but we have many things in common .',\n",
              " 'We love to travel , we love music , we love to be in places like this , and we started to bring Mario with us just to show to him the best things that we can show to him .',\n",
              " 'This short video is from last week .',\n",
              " 'I am not saying -- — I am not saying it &apos;s a miracle . That &apos;s not the message , because we are just at the beginning of the path .',\n",
              " 'But we want to share what was the key learning , the key learning that Mario drove to us , and it is to consider what you have as a gift and not only what you miss , and to consider what you miss just as an opportunity .',\n",
              " 'And this is the message that we want to share with you .',\n",
              " 'This is why we are here .',\n",
              " 'Mario !',\n",
              " 'And this is why -- — And this is why we decided to share the best mirror in the world with him .',\n",
              " 'And we thank you so much , all of you .',\n",
              " 'Thank you . Thank you . Bye .',\n",
              " 'Thank you .',\n",
              " 'Mark Shaw : One very dry demo',\n",
              " 'Mark Shaw demos Ultra-Ever Dry , a liquid-repellent coating that acts as an astonishingly powerful shield against water and water-based materials . At the nano level , the spray covers a surface with an umbrella of air so that water bounces right off . Watch for an exciting two-minute kicker .',\n",
              " 'I &apos;m here to show you how something you can &apos;t see can be so much fun to look at .',\n",
              " 'You &apos;re about to experience a new , available and exciting technology that &apos;s going to make us rethink how we waterproof our lives .',\n",
              " 'What I have here is a cinder block that we &apos;ve coated half with a nanotechnology spray that can be applied to almost any material .',\n",
              " 'It &apos;s called Ultra-Ever Dry , and when you apply it to any material , it turns into a superhydrophobic shield .',\n",
              " 'So this is a cinder block , uncoated , and you can see that it &apos;s porous , it absorbs water .',\n",
              " 'Not anymore .',\n",
              " 'Porous , nonporous .',\n",
              " 'So what &apos;s superhydrophobic ?',\n",
              " 'Superhydrophobic is how we measure a drop of water on a surface .',\n",
              " 'The rounder it is , the more hydrophobic it is , and if it &apos;s really round , it &apos;s superhydrophobic .',\n",
              " 'A freshly waxed car , the water molecules slump to about 90 degrees .',\n",
              " 'A windshield coating is going to give you about 110 degrees .',\n",
              " 'But what you &apos;re seeing here is 160 to 175 degrees , and anything over 150 is superhydrophobic .',\n",
              " 'So as part of the demonstration , what I have is a pair of gloves , and we &apos;ve coated one of the gloves with the nanotechnology coating , and let &apos;s see if you can tell which one , and I &apos;ll give you a hint .',\n",
              " 'Did you guess the one that was dry ?',\n",
              " 'When you have nanotechnology and nanoscience , what &apos;s occurred is that we &apos;re able to now look at atoms and molecules and actually control them for great benefits .',\n",
              " 'And we &apos;re talking really small here .',\n",
              " 'The way you measure nanotechnology is in nanometers , and one nanometer is a billionth of a meter , and to put some scale to that , if you had a nanoparticle that was one nanometer thick , and you put it side by side , and you had 50,000 of them , you &apos;d be the width of a human hair .',\n",
              " 'So very small , but very useful .',\n",
              " 'And it &apos;s not just water that this works with .',\n",
              " 'It &apos;s a lot of water-based materials like concrete , water-based paint , mud , and also some refined oils as well .',\n",
              " 'You can see the difference .',\n",
              " 'Moving onto the next demonstration , we &apos;ve taken a pane of glass and we &apos;ve coated the outside of it , we &apos;ve framed it with the nanotechnology coating , and we &apos;re going to pour this green-tinted water inside the middle , and you &apos;re going to see , it &apos;s going to spread out on glass like you &apos;d normally think it would , except when it hits the coating , it stops , and I can &apos;t even coax it to leave .',\n",
              " 'It &apos;s that afraid of the water .',\n",
              " 'So what &apos;s going on here ? What &apos;s happening ?',\n",
              " 'Well , the surface of the spray coating is actually filled with nanoparticles that form a very rough and craggly surface .',\n",
              " 'You &apos;d think it &apos;d be smooth , but it &apos;s actually not .',\n",
              " 'And it has billions of interstitial spaces , and those spaces , along with the nanoparticles , reach up and grab the air molecules , and cover the surface with air .',\n",
              " 'It &apos;s an umbrella of air all across it , and that layer of air is what the water hits , the mud hits , the concrete hits , and it glides right off .',\n",
              " 'So if I put this inside this water here , you can see a silver reflective coating around it , and that silver reflective coating is the layer of air that &apos;s protecting the water from touching the paddle , and it &apos;s dry .',\n",
              " 'So what are the applications ?',\n",
              " 'I mean , many of you right now are probably going through your head .',\n",
              " 'Everyone that sees this gets excited , and says , &quot; Oh , I could use it for this and this and this . &quot;',\n",
              " 'The applications in a general sense could be anything that &apos;s anti-wetting .',\n",
              " 'We &apos;ve certainly seen that today .',\n",
              " 'It could be anything that &apos;s anti-icing , because if you don &apos;t have water , you don &apos;t have ice .',\n",
              " 'It could be anti-corrosion .',\n",
              " 'No water , no corrosion .',\n",
              " 'It could be anti-bacterial .',\n",
              " 'Without water , the bacteria won &apos;t survive .',\n",
              " 'And it could be things that need to be self-cleaning as well .',\n",
              " 'So imagine how something like this could help revolutionize your field of work .',\n",
              " 'And I &apos;m going to leave you with one last demonstration , but before I do that , I would like to say thank you , and think small .',\n",
              " 'It &apos;s going to happen . Wait for it . Wait for it .',\n",
              " 'You guys didn &apos;t hear about us cutting out the Design from TED ?',\n",
              " '&#91; Two minutes later ... &#93; He ran into all sorts of problems in terms of managing the medical research part .',\n",
              " 'It &apos;s happening !',\n",
              " '',\n",
              " 'Dan Ariely : Our buggy moral code',\n",
              " 'Behavioral economist Dan Ariely studies the bugs in our moral code : the hidden reasons we think it &apos;s OK to cheat or steal . Clever studies help make his point that we &apos;re predictably irrational -- and can be influenced in ways we can &apos;t grasp .',\n",
              " 'I want to talk to you today a little bit about predictable irrationality .',\n",
              " 'And my interest in irrational behavior started many years ago in the hospital .',\n",
              " 'I was burned very badly .',\n",
              " 'And if you spend a lot of time in hospital , you &apos;ll see a lot of types of irrationalities .',\n",
              " 'And the one that particularly bothered me in the burn department was the process by which the nurses took the bandage off me .',\n",
              " 'Now , you must have all taken a Band-Aid off at some point , and you must have wondered what &apos;s the right approach .',\n",
              " 'Do you rip it off quickly -- short duration but high intensity -- or do you take your Band-Aid off slowly -- you take a long time , but each second is not as painful -- which one of those is the right approach ?',\n",
              " 'The nurses in my department thought that the right approach was the ripping one , so they would grab hold and they would rip , and they would grab hold and they would rip .',\n",
              " 'And because I had 70 percent of my body burned , it would take about an hour .',\n",
              " 'And as you can imagine , I hated that moment of ripping with incredible intensity .',\n",
              " 'And I would try to reason with them and say , &quot; Why don &apos;t we try something else ?',\n",
              " 'Why don &apos;t we take it a little longer -- maybe two hours instead of an hour -- and have less of this intensity ? &quot;',\n",
              " 'And the nurses told me two things .',\n",
              " 'They told me that they had the right model of the patient -- that they knew what was the right thing to do to minimize my pain -- and they also told me that the word patient doesn &apos;t mean to make suggestions or to interfere or ...',\n",
              " 'This is not just in Hebrew , by the way .',\n",
              " 'It &apos;s in every language I &apos;ve had experience with so far .',\n",
              " 'And , you know , there &apos;s not much -- there wasn &apos;t much I could do , and they kept on doing what they were doing .',\n",
              " 'And about three years later , when I left the hospital , I started studying at the university .',\n",
              " 'And one of the most interesting lessons I learned was that there is an experimental method that if you have a question you can create a replica of this question in some abstract way , and you can try to examine this question , maybe learn something about the world .',\n",
              " 'So that &apos;s what I did .',\n",
              " 'I was still interested in this question of how do you take bandages off burn patients .',\n",
              " 'So originally I didn &apos;t have much money , so I went to a hardware store and I bought a carpenter &apos;s vice .',\n",
              " 'And I would bring people to the lab and I would put their finger in it , and I would crunch it a little bit .',\n",
              " 'And I would crunch it for long periods and short periods , and pain that went up and pain that went down , and with breaks and without breaks -- all kinds of versions of pain .',\n",
              " 'And when I finished hurting people a little bit , I would ask them , so , how painful was this ? Or , how painful was this ?',\n",
              " 'Or , if you had to choose between the last two , which one would you choose ?',\n",
              " 'I kept on doing this for a while .',\n",
              " 'And then , like all good academic projects , I got more funding .',\n",
              " 'I moved to sounds , electrical shocks -- I even had a pain suit that I could get people to feel much more pain .',\n",
              " 'But at the end of this process , what I learned was that the nurses were wrong .',\n",
              " 'Here were wonderful people with good intentions and plenty of experience , and nevertheless they were getting things wrong predictably all the time .',\n",
              " 'It turns out that because we don &apos;t encode duration in the way that we encode intensity , I would have had less pain if the duration would have been longer and the intensity was lower .',\n",
              " 'It turns out it would have been better to start with my face , which was much more painful , and move toward my legs , giving me a trend of improvement over time -- that would have been also less painful .',\n",
              " 'And it also turns out that it would have been good to give me breaks in the middle to kind of recuperate from the pain .',\n",
              " 'All of these would have been great things to do , and my nurses had no idea .',\n",
              " 'And from that point on I started thinking , are the nurses the only people in the world who get things wrong in this particular decision , or is it a more general case ?',\n",
              " 'And it turns out it &apos;s a more general case -- there &apos;s a lot of mistakes we do .',\n",
              " 'And I want to give you one example of one of these irrationalities , and I want to talk to you about cheating .',\n",
              " 'And the reason I picked cheating is because it &apos;s interesting , but also it tells us something , I think , about the stock market situation we &apos;re in .',\n",
              " 'So , my interest in cheating started when Enron came on the scene , exploded all of a sudden , and I started thinking about what is happening here .',\n",
              " 'Is it the case that there was kind of a few apples who are capable of doing these things , or are we talking a more endemic situation , that many people are actually capable of behaving this way ?',\n",
              " 'So , like we usually do , I decided to do a simple experiment .',\n",
              " 'And here &apos;s how it went .',\n",
              " 'If you were in the experiment , I would pass you a sheet of paper with 20 simple math problems that everybody could solve , but I wouldn &apos;t give you enough time .',\n",
              " 'When the five minutes were over , I would say , &quot; Pass me the sheets of paper , and I &apos;ll pay you a dollar per question . &quot;',\n",
              " 'People did this . I would pay people four dollars for their task -- on average people would solve four problems .',\n",
              " 'Other people I would tempt to cheat .',\n",
              " 'I would pass their sheet of paper .',\n",
              " 'When the five minutes were over , I would say , &quot; Please shred the piece of paper .',\n",
              " 'Put the little pieces in your pocket or in your backpack , and tell me how many questions you got correctly . &quot;',\n",
              " 'People now solved seven questions on average .',\n",
              " 'Now , it wasn &apos;t as if there was a few bad apples -- a few people cheated a lot .',\n",
              " 'Instead , what we saw is a lot of people who cheat a little bit .',\n",
              " 'Now , in economic theory , cheating is a very simple cost-benefit analysis .',\n",
              " 'You say , what &apos;s the probability of being caught ?',\n",
              " 'How much do I stand to gain from cheating ?',\n",
              " 'And how much punishment would I get if I get caught ?',\n",
              " 'And you weigh these options out -- you do the simple cost-benefit analysis , and you decide whether it &apos;s worthwhile to commit the crime or not .',\n",
              " 'So , we try to test this .',\n",
              " 'For some people , we varied how much money they could get away with -- how much money they could steal .',\n",
              " 'We paid them 10 cents per correct question , 50 cents , a dollar , five dollars , 10 dollars per correct question .',\n",
              " 'You would expect that as the amount of money on the table increases , people would cheat more , but in fact it wasn &apos;t the case .',\n",
              " 'We got a lot of people cheating by stealing by a little bit .',\n",
              " 'What about the probability of being caught ?',\n",
              " 'Some people shredded half the sheet of paper , so there was some evidence left .',\n",
              " 'Some people shredded the whole sheet of paper .',\n",
              " 'Some people shredded everything , went out of the room , and paid themselves from the bowl of money that had over 100 dollars .',\n",
              " 'You would expect that as the probability of being caught goes down , people would cheat more , but again , this was not the case .',\n",
              " 'Again , a lot of people cheated by just by a little bit , and they were insensitive to these economic incentives .',\n",
              " 'So we said , &quot; If people are not sensitive to the economic rational theory explanations , to these forces , what could be going on ? &quot;',\n",
              " 'And we thought maybe what is happening is that there are two forces .',\n",
              " 'At one hand , we all want to look at ourselves in the mirror and feel good about ourselves , so we don &apos;t want to cheat .',\n",
              " 'On the other hand , we can cheat a little bit , and still feel good about ourselves .',\n",
              " 'So , maybe what is happening is that there &apos;s a level of cheating we can &apos;t go over , but we can still benefit from cheating at a low degree , as long as it doesn &apos;t change our impressions about ourselves .',\n",
              " 'We call this like a personal fudge factor .',\n",
              " 'Now , how would you test a personal fudge factor ?',\n",
              " 'Initially we said , what can we do to shrink the fudge factor ?',\n",
              " 'So , we got people to the lab , and we said , &quot; We have two tasks for you today . &quot;',\n",
              " 'First , we asked half the people to recall either 10 books they read in high school , or to recall The Ten Commandments , and then we tempted them with cheating .',\n",
              " 'Turns out the people who tried to recall The Ten Commandments -- and in our sample nobody could recall all of The Ten Commandments -- but those people who tried to recall The Ten Commandments , given the opportunity to cheat , did not cheat at all .',\n",
              " 'It wasn &apos;t that the more religious people -- the people who remembered more of the Commandments -- cheated less , and the less religious people -- the people who couldn &apos;t remember almost any Commandments -- cheated more .',\n",
              " 'The moment people thought about trying to recall The Ten Commandments , they stopped cheating .',\n",
              " 'In fact , even when we gave self-declared atheists the task of swearing on the Bible and we give them a chance to cheat , they don &apos;t cheat at all .',\n",
              " 'Now , Ten Commandments is something that is hard to bring into the education system , so we said , &quot; Why don &apos;t we get people to sign the honor code ? &quot;',\n",
              " 'So , we got people to sign , &quot; I understand that this short survey falls under the MIT Honor Code . &quot;',\n",
              " 'Then they shredded it . No cheating whatsoever .',\n",
              " 'And this is particularly interesting , because MIT doesn &apos;t have an honor code .',\n",
              " 'So , all this was about decreasing the fudge factor .',\n",
              " 'What about increasing the fudge factor ?',\n",
              " 'The first experiment -- I walked around MIT and I distributed six-packs of Cokes in the refrigerators -- these were common refrigerators for the undergrads .',\n",
              " 'And I came back to measure what we technically call the half-lifetime of Coke -- how long does it last in the refrigerators ?',\n",
              " 'As you can expect it doesn &apos;t last very long ; people take it .',\n",
              " 'In contrast , I took a plate with six one-dollar bills , and I left those plates in the same refrigerators .',\n",
              " 'No bill ever disappeared .',\n",
              " 'Now , this is not a good social science experiment , so to do it better I did the same experiment as I described to you before .',\n",
              " 'A third of the people we passed the sheet , they gave it back to us .',\n",
              " 'A third of the people we passed it to , they shredded it , they came to us and said , &quot; Mr. Experimenter , I solved X problems . Give me X dollars . &quot;',\n",
              " 'A third of the people , when they finished shredding the piece of paper , they came to us and said , &quot; Mr Experimenter , I solved X problems . Give me X tokens . &quot;',\n",
              " 'We did not pay them with dollars ; we paid them with something else .',\n",
              " 'And then they took the something else , they walked 12 feet to the side , and exchanged it for dollars .',\n",
              " 'Think about the following intuition .',\n",
              " 'How bad would you feel about taking a pencil from work home , compared to how bad would you feel about taking 10 cents from a petty cash box ?',\n",
              " 'These things feel very differently .',\n",
              " 'Would being a step removed from cash for a few seconds by being paid by token make a difference ?',\n",
              " 'Our subjects doubled their cheating .',\n",
              " 'I &apos;ll tell you what I think about this and the stock market in a minute .',\n",
              " 'But this did not solve the big problem I had with Enron yet , because in Enron , there &apos;s also a social element .',\n",
              " 'People see each other behaving .',\n",
              " 'In fact , every day when we open the news we see examples of people cheating .',\n",
              " 'What does this cause us ?',\n",
              " 'So , we did another experiment .',\n",
              " 'We got a big group of students to be in the experiment , and we prepaid them .',\n",
              " 'So everybody got an envelope with all the money for the experiment , and we told them that at the end , we asked them to pay us back the money they didn &apos;t make . OK ?',\n",
              " 'The same thing happens .',\n",
              " 'When we give people the opportunity to cheat , they cheat .',\n",
              " 'They cheat just by a little bit , all the same .',\n",
              " 'But in this experiment we also hired an acting student .',\n",
              " 'This acting student stood up after 30 seconds , and said , &quot; I solved everything . What do I do now ? &quot;',\n",
              " 'And the experimenter said , &quot; If you &apos;ve finished everything , go home .',\n",
              " 'That &apos;s it . The task is finished . &quot;',\n",
              " 'So , now we had a student -- an acting student -- that was a part of the group .',\n",
              " 'Nobody knew it was an actor .',\n",
              " 'And they clearly cheated in a very , very serious way .',\n",
              " 'What would happen to the other people in the group ?',\n",
              " 'Will they cheat more , or will they cheat less ?',\n",
              " 'Here is what happens .',\n",
              " 'It turns out it depends on what kind of sweatshirt they &apos;re wearing .',\n",
              " 'Here is the thing .',\n",
              " 'We ran this at Carnegie Mellon and Pittsburgh .',\n",
              " 'And at Pittsburgh there are two big universities , Carnegie Mellon and University of Pittsburgh .',\n",
              " 'All of the subjects sitting in the experiment were Carnegie Mellon students .',\n",
              " 'When the actor who was getting up was a Carnegie Mellon student -- he was actually a Carnegie Mellon student -- but he was a part of their group , cheating went up .',\n",
              " 'But when he actually had a University of Pittsburgh sweatshirt , cheating went down .',\n",
              " 'Now , this is important , because remember , when the moment the student stood up , it made it clear to everybody that they could get away with cheating , because the experimenter said , &quot; You &apos;ve finished everything . Go home , &quot; and they went with the money .',\n",
              " 'So it wasn &apos;t so much about the probability of being caught again .',\n",
              " 'It was about the norms for cheating .',\n",
              " 'If somebody from our in-group cheats and we see them cheating , we feel it &apos;s more appropriate , as a group , to behave this way .',\n",
              " 'But if it &apos;s somebody from another group , these terrible people -- I mean , not terrible in this -- but somebody we don &apos;t want to associate ourselves with , from another university , another group , all of a sudden people &apos;s awareness of honesty goes up -- a little bit like The Ten Commandments experiment -- and people cheat even less .',\n",
              " 'So , what have we learned from this about cheating ?',\n",
              " 'We &apos;ve learned that a lot of people can cheat .',\n",
              " 'They cheat just by a little bit .',\n",
              " 'When we remind people about their morality , they cheat less .',\n",
              " 'When we get bigger distance from cheating , from the object of money , for example , people cheat more .',\n",
              " 'And when we see cheating around us , particularly if it &apos;s a part of our in-group , cheating goes up .',\n",
              " 'Now , if we think about this in terms of the stock market , think about what happens .',\n",
              " 'What happens in a situation when you create something where you pay people a lot of money to see reality in a slightly distorted way ?',\n",
              " 'Would they not be able to see it this way ?',\n",
              " 'Of course they would .',\n",
              " 'What happens when you do other things , like you remove things from money ?',\n",
              " 'You call them stock , or stock options , derivatives , mortgage-backed securities .',\n",
              " 'Could it be that with those more distant things , it &apos;s not a token for one second , it &apos;s something that is many steps removed from money for a much longer time -- could it be that people will cheat even more ?',\n",
              " 'And what happens to the social environment when people see other people behave around them ?',\n",
              " 'I think all of those forces worked in a very bad way in the stock market .',\n",
              " 'More generally , I want to tell you something about behavioral economics .',\n",
              " 'We have many intuitions in our life , and the point is that many of these intuitions are wrong .',\n",
              " 'The question is , are we going to test those intuitions ?',\n",
              " 'We can think about how we &apos;re going to test this intuition in our private life , in our business life , and most particularly when it goes to policy , when we think about things like No Child Left Behind , when you create new stock markets , when you create other policies -- taxation , health care and so on .',\n",
              " 'And the difficulty of testing our intuition was the big lesson I learned when I went back to the nurses to talk to them .',\n",
              " 'So I went back to talk to them and tell them what I found out about removing bandages .',\n",
              " 'And I learned two interesting things .',\n",
              " 'One was that my favorite nurse , Ettie , told me that I did not take her pain into consideration .',\n",
              " 'She said , &quot; Of course , you know , it was very painful for you .',\n",
              " 'But think about me as a nurse , taking , removing the bandages of somebody I liked , and had to do it repeatedly over a long period of time .',\n",
              " 'Creating so much torture was not something that was good for me , too . &quot;',\n",
              " 'And she said maybe part of the reason was it was difficult for her .',\n",
              " 'But it was actually more interesting than that , because she said , &quot; I did not think that your intuition was right .',\n",
              " 'I felt my intuition was correct . &quot;',\n",
              " 'So , if you think about all of your intuitions , it &apos;s very hard to believe that your intuition is wrong .',\n",
              " 'And she said , &quot; Given the fact that I thought my intuition was right ... &quot; -- she thought her intuition was right -- it was very difficult for her to accept doing a difficult experiment to try and check whether she was wrong .',\n",
              " 'But in fact , this is the situation we &apos;re all in all the time .',\n",
              " 'We have very strong intuitions about all kinds of things -- our own ability , how the economy works , how we should pay school teachers .',\n",
              " 'But unless we start testing those intuitions , we &apos;re not going to do better .',\n",
              " 'And just think about how better my life would have been if these nurses would have been willing to check their intuition , and how everything would have been better if we just start doing more systematic experimentation of our intuitions .',\n",
              " 'Thank you very much .',\n",
              " 'Jane McGonigal : Massively multi-player … thumb-wrestling ?',\n",
              " 'What happens when you get an entire audience to stand up and connect with one another ? Chaos , that &apos;s what . At least , that &apos;s what happened when Jane McGonigal tried to teach TED to play her favorite game . Then again , when the game is &quot; massively multiplayer thumb-wrestling , &quot; what else would you expect ?',\n",
              " 'Today I am going to teach you how to play my favorite game : massively multiplayer thumb-wrestling .',\n",
              " 'It &apos;s the only game in the world that I know of that allows you , the player , the opportunity to experience 10 positive emotions in 60 seconds or less .',\n",
              " 'This is true , so if you play this game with me today for just one single minute , you will get to feel joy , relief , love , surprise , pride , curiosity , excitement , awe and wonder , contentment , and creativity , all in the span of one minute .',\n",
              " 'So this sounds pretty good , right ? Now you &apos;re willing to play .',\n",
              " 'In order to teach you this game , I &apos;m going to need some volunteers to come up onstage really quickly , and we &apos;re going to do a little hands-on demo .',\n",
              " 'While they &apos;re coming up , I should let you know , this game was invented 10 years ago by an artists &apos; collective in Austria named Monochrom .',\n",
              " 'So thank you , Monochrom .',\n",
              " 'Okay , so most people are familiar with traditional , two-person thumb-wrestling .',\n",
              " 'Sunni , let &apos;s just remind them .',\n",
              " 'One , two , three , four , I declare a thumb war , and we wrestle , and of course Sunni beats me because she &apos;s the best .',\n",
              " 'Now the first thing about massively multiplayer thumb-wrestling , we &apos;re the gamer generation .',\n",
              " 'There are a billion gamers on the planet now , so we need more of a challenge .',\n",
              " 'So the first thing we need is more thumbs .',\n",
              " 'So Eric , come on over .',\n",
              " 'So we could get three thumbs together , and Peter could join us .',\n",
              " 'We could even have four thumbs together , and the way you win is you &apos;re the first person to pin someone else &apos;s thumb .',\n",
              " 'This is really important . You can &apos;t , like , wait while they fight it out and then swoop in at the last minute .',\n",
              " 'That is not how you win .',\n",
              " 'Ah , who did that ? Eric you did that .',\n",
              " 'So Eric would have won . He was the first person to pin my thumb .',\n",
              " 'Okay , so that &apos;s the first rule , and we can see that three or four is kind of the typical number of thumbs in a node , but if you feel ambitious , you don &apos;t have to hold back .',\n",
              " 'We can really go for it .',\n",
              " 'So you can see up here .',\n",
              " 'Now the only other rule you need to remember is , gamer generation , we like a challenge .',\n",
              " 'I happen to notice you all have some thumbs you &apos;re not using .',\n",
              " 'So I think we should kind of get some more involved .',\n",
              " 'And if we had just four people , we would do it just like this , and we would try and wrestle both thumbs at the same time .',\n",
              " 'Perfect .',\n",
              " 'Now , if we had more people in the room , instead of just wrestling in a closed node , we might reach out and try and grab some other people .',\n",
              " 'And in fact , that &apos;s what we &apos;re going to do right now .',\n",
              " 'We &apos;re going to try and get all , something like , I don &apos;t know , 1,500 thumbs in this room connected in a single node .',\n",
              " 'And we have to connect both levels , so if you &apos;re up there , you &apos;re going to be reaching down and reaching up .',\n",
              " 'Now — — before we get started -- This is great . You &apos;re excited to play . — before we get started , can I have the slides back up here really quick , because if you get good at this game , I want you to know there are some advanced levels .',\n",
              " 'So this is the kind of simple level , right ?',\n",
              " 'But there are advanced configurations .',\n",
              " 'This is called the Death Star Configuration .',\n",
              " 'Any Star Wars fans ?',\n",
              " 'And this one &apos;s called the Möbius Strip .',\n",
              " 'Any science geeks , you get that one .',\n",
              " 'This is the hardest level . This is the extreme .',\n",
              " 'So we &apos;ll stick with the normal one for now , and I &apos;m going to give you 30 seconds , every thumb into the node , connect the upper and the lower levels , you guys go on down there .',\n",
              " 'Thirty seconds . Into the network . Make the node .',\n",
              " 'Stand up ! It &apos;s easier if you stand up .',\n",
              " 'Everybody , up up up up up !',\n",
              " 'Stand up , my friends .',\n",
              " 'All right .',\n",
              " 'Don &apos;t start wrestling yet .',\n",
              " 'If you have a free thumb , wave it around , make sure it gets connected .',\n",
              " 'Okay . We need to do a last-minute thumb check .',\n",
              " 'If you have a free thumb , wave it around to make sure .',\n",
              " 'Grab that thumb !',\n",
              " 'Reach behind you . There you go .',\n",
              " 'Any other thumbs ?',\n",
              " 'Okay , on the count of three , you &apos;re going to go .',\n",
              " 'Try to keep track . Grab , grab , grab it .',\n",
              " 'Okay ? One , two , three , go !',\n",
              " 'Did you win ? You got it ? You got it ? Excellent !',\n",
              " 'Well done . Thank you . Thank you very much .',\n",
              " 'All right .',\n",
              " 'While you are basking in the glow of having won your first massively multiplayer thumb-wrestling game , let &apos;s do a quick recap on the positive emotions .',\n",
              " 'So curiosity .',\n",
              " 'I said &quot; massively multiplayer thumb-wrestling . &quot;',\n",
              " 'You were like , &quot; What the hell is she talking about ? &quot;',\n",
              " 'So I provoked a little curiosity .',\n",
              " 'Creativity : it took creativity to solve the problem of getting all the thumbs into the node .',\n",
              " 'I &apos;m reaching around and I &apos;m reaching up .',\n",
              " 'So you used creativity . That was great .',\n",
              " 'How about surprise ? The actual feeling of trying to wrestle two thumbs at once is pretty surprising .',\n",
              " 'You heard that sound go up in the room .',\n",
              " 'We had excitement . As you started to wrestle , maybe you &apos;re starting to win or this person &apos;s , like , really into it , so you kind of get the excitement going .',\n",
              " 'We have relief . You got to stand up .',\n",
              " 'You &apos;ve been sitting for awhile , so the physical relief , getting to shake it out .',\n",
              " 'We had joy . You were laughing , smiling . Look at your faces . This room is full of joy .',\n",
              " 'We had some contentment .',\n",
              " 'I didn &apos;t see anybody sending text messages or checking their email while we were playing , so you were totally content to be playing .',\n",
              " 'The most important three emotions , awe and wonder , we had everybody connected physically for a minute .',\n",
              " 'When was the last time you were at TED and you got to connect physically with every single person in the room ?',\n",
              " 'And it &apos;s truly awesome and wondrous .',\n",
              " 'And speaking of physical connection , you guys know I love the hormone oxytocin , you release oxytocin , you feel bonded to everyone in the room .',\n",
              " 'You guys know that the best way to release oxytocin quickly is to hold someone else &apos;s hand for at least six seconds .',\n",
              " 'You guys were all holding hands for way more than six seconds , so we are all now biochemically primed to love each other . That is great .',\n",
              " 'And the last emotion of pride .',\n",
              " 'How many people are like me . Just admit it .',\n",
              " 'You lost both your thumbs .',\n",
              " 'It just didn &apos;t work out for you .',\n",
              " 'That &apos;s okay , because you learned a new skill today .',\n",
              " 'You learned , from scratch , a game you never knew before .',\n",
              " 'Now you know how to play it . You can teach other people .',\n",
              " 'So congratulations .',\n",
              " 'How many of you won just won thumb ?',\n",
              " 'All right . I have very good news for you .',\n",
              " 'According to the official rules of massively multiplayer thumb-wrestling , this makes you a grandmaster of the game .',\n",
              " 'Because there aren &apos;t that many people who know how to play , we have to kind of accelerate the program more than a game like chess .',\n",
              " 'So congratulations , grandmasters .',\n",
              " 'Win one thumb once , you will become a grandmaster .',\n",
              " 'Did anybody win both their thumbs ?',\n",
              " 'Yes . Awesome . Okay .',\n",
              " 'Get ready to update your Twitter or Facebook status .',\n",
              " 'You guys , according to the rules , are legendary grandmasters , so congratulations .',\n",
              " 'I will just leave you with this tip , if you want to play again .',\n",
              " 'The best way to become a legendary grandmaster , you &apos;ve got your two nodes going on .',\n",
              " 'Pick off the one that looks easiest .',\n",
              " 'They &apos;re not paying attention . They look kind of weak .',\n",
              " 'Focus on that one and do something crazy with this arm .',\n",
              " 'As soon as you win , suddenly stop .',\n",
              " 'Everybody is thrown off . You go in for the kill .',\n",
              " 'That &apos;s how you become a legendary grandmaster of massively multiplayer thumb-wrestling .',\n",
              " 'Thank you for letting me teach you my favorite game .',\n",
              " 'Wooo !',\n",
              " 'Thank you .',\n",
              " 'David Byrne : How architecture helped music evolve',\n",
              " 'As his career grew , David Byrne went from playing CBGB to Carnegie Hall . He asks : Does the venue make the music ? From outdoor drumming to Wagnerian operas to arena rock , he explores how context has pushed musical innovation .',\n",
              " 'This is the venue where , as a young man , some of the music that I wrote was first performed .',\n",
              " 'It was , remarkably , a pretty good sounding room .',\n",
              " 'With all the uneven walls and all the crap everywhere , it actually sounded pretty good .',\n",
              " 'This is a song that was recorded there .',\n",
              " 'This is not Talking Heads , in the picture anyway .',\n",
              " '&quot; by Talking Heads ) So the nature of the room meant that words could be understood .',\n",
              " 'The lyrics of the songs could be pretty much understood .',\n",
              " 'The sound system was kind of decent .',\n",
              " 'And there wasn &apos;t a lot of reverberation in the room .',\n",
              " 'So the rhythms could be pretty intact too , pretty concise .',\n",
              " 'Other places around the country had similar rooms .',\n",
              " 'This is Tootsie &apos;s Orchid Lounge in Nashville .',\n",
              " 'The music was in some ways different , but in structure and form , very much the same .',\n",
              " 'The clientele behavior was very much the same too .',\n",
              " 'And so the bands at Tootsie &apos;s or at CBGB &apos;s had to play loud enough -- the volume had to be loud enough to overcome people falling down , shouting out and doing whatever else they were doing .',\n",
              " 'Since then , I &apos;ve played other places that are much nicer .',\n",
              " 'I &apos;ve played the Disney Hall here and Carnegie Hall and places like that .',\n",
              " 'And it &apos;s been very exciting .',\n",
              " 'But I also noticed that sometimes the music that I had written , or was writing at the time , didn &apos;t sound all that great in some of those halls .',\n",
              " 'We managed , but sometimes those halls didn &apos;t seem exactly suited to the music I was making or had made .',\n",
              " 'So I asked myself : Do I write stuff for specific rooms ?',\n",
              " 'Do I have a place , a venue , in mind when I write ?',\n",
              " 'Is that a kind of model for creativity ?',\n",
              " 'Do we all make things with a venue , a context , in mind ?',\n",
              " 'Okay , Africa .',\n",
              " 'Most of the popular music that we know now has a big part of its roots in West Africa .',\n",
              " 'And the music there , I would say , the instruments , the intricate rhythms , the way it &apos;s played , the setting , the context , it &apos;s all perfect . It all works perfect .',\n",
              " 'The music works perfectly in that setting .',\n",
              " 'There &apos;s no big room to create reverberation and confuse the rhythms .',\n",
              " 'The instruments are loud enough that they can be heard without amplification , etc . , etc .',\n",
              " 'It &apos;s no accident .',\n",
              " 'It &apos;s perfect for that particular context .',\n",
              " 'And it would be a mess in a context like this . This is a gothic cathedral .',\n",
              " 'In a gothic cathedral , this kind of music is perfect .',\n",
              " 'It doesn &apos;t change key , the notes are long , there &apos;s almost no rhythm whatsoever , and the room flatters the music .',\n",
              " 'It actually improves it .',\n",
              " 'This is the room that Bach wrote some of his music for . This is the organ .',\n",
              " 'It &apos;s not as big as a gothic cathedral , so he can write things that are a little bit more intricate .',\n",
              " 'He can , very innovatively , actually change keys without risking huge dissonances .',\n",
              " 'This is a little bit later .',\n",
              " 'This is the kind of rooms that Mozart wrote in .',\n",
              " 'I think we &apos;re in like 1770 , somewhere around there .',\n",
              " 'They &apos;re smaller , even less reverberant , so he can write really frilly music that &apos;s very intricate -- and it works .',\n",
              " 'It fits the room perfectly .',\n",
              " 'This is La Scala .',\n",
              " 'It &apos;s around the same time , I think it was built around 1776 .',\n",
              " 'People in the audience in these opera houses , when they were built , they used to yell out to one another .',\n",
              " 'They used to eat , drink and yell out to people on the stage , just like they do at CBGB &apos;s and places like that .',\n",
              " 'If they liked an aria , they would holler and suggest that it be done again as an encore , not at the end of the show , but immediately .',\n",
              " 'And well , that was an opera experience .',\n",
              " 'This is the opera house that Wagner built for himself .',\n",
              " 'And the size of the room is not that big .',\n",
              " 'It &apos;s smaller than this .',\n",
              " 'But Wagner made an innovation .',\n",
              " 'He wanted a bigger band .',\n",
              " 'He wanted a little more bombast , so he increased the size of the orchestra pit so he could get more low-end instruments in there .',\n",
              " 'Okay .',\n",
              " 'This is Carnegie Hall .',\n",
              " 'Obviously , this kind of thing became popular .',\n",
              " 'The halls got bigger . Carnegie Hall &apos;s fair-sized .',\n",
              " 'It &apos;s larger than some of the other symphony halls .',\n",
              " 'And they &apos;re a lot more reverberant than La Scala .',\n",
              " 'Around the same , according to Alex Ross who writes for the New Yorker , this kind of rule came into effect that audiences had to be quiet -- no more eating , drinking and yelling at the stage , or gossiping with one another during the show .',\n",
              " 'They had to be very quiet .',\n",
              " 'So those two things combined meant that a different kind of music worked best in these kind of halls .',\n",
              " 'It meant that there could be extreme dynamics , which there weren &apos;t in some of these other kinds of music .',\n",
              " 'Quiet parts could be heard that would have been drowned out by all the gossiping and shouting .',\n",
              " 'But because of the reverberation in those rooms like Carnegie Hall , the music had to be maybe a little less rhythmic and a little more textural .',\n",
              " 'This is Mahler .',\n",
              " 'It looks like Bob Dylan , but it &apos;s Mahler .',\n",
              " 'That was Bob &apos;s last record , yeah .',\n",
              " 'Popular music , coming along at the same time .',\n",
              " 'This is a jazz band .',\n",
              " 'According to Scott Joplin , the bands were playing on riverboats and clubs .',\n",
              " 'Again , it &apos;s noisy . They &apos;re playing for dancers .',\n",
              " 'There &apos;s certain sections of the song -- the songs had different sections that the dancers really liked .',\n",
              " 'And they &apos;d say , &quot; Play that part again . &quot;',\n",
              " 'Well , there &apos;s only so many times you can play the same section of a song over and over again for the dancers .',\n",
              " 'So the bands started to improvise new melodies .',\n",
              " 'And a new form of music was born .',\n",
              " 'These are played mainly in small rooms .',\n",
              " 'People are dancing , shouting and drinking .',\n",
              " 'So the music has to be loud enough to be heard above that .',\n",
              " 'Same thing goes true for -- that &apos;s the beginning of the century -- for the whole of 20th-century popular music , whether it &apos;s rock or Latin music or whatever .',\n",
              " '&#91; Live music &#93; doesn &apos;t really change that much .',\n",
              " 'It changes about a third of the way into the 20th century , when this became one of the primary venues for music .',\n",
              " 'And this was one way that the music got there .',\n",
              " 'Microphones enabled singers , in particular , and musicians and composers , to completely change the kind of music that they were writing .',\n",
              " 'So far , a lot of the stuff that was on the radio was live music , but singers , like Frank Sinatra , could use the mic and do things that they could never do without a microphone .',\n",
              " 'Other singers after him went even further .',\n",
              " 'This is Chet Baker .',\n",
              " 'And this kind of thing would have been impossible without a microphone .',\n",
              " 'It would have been impossible without recorded music as well .',\n",
              " 'And he &apos;s singing right into your ear .',\n",
              " 'He &apos;s whispering into your ears .',\n",
              " 'The effect is just electric .',\n",
              " 'It &apos;s like the guy is sitting next to you , whispering who knows what into your ear .',\n",
              " 'So at this point , music diverged .',\n",
              " 'There &apos;s live music , and there &apos;s recorded music .',\n",
              " 'And they no longer have to be exactly the same .',\n",
              " 'Now there &apos;s venues like this , a discotheque , and there &apos;s jukeboxes in bars , where you don &apos;t even need to have a band .',\n",
              " 'There doesn &apos;t need to be any live performing musicians whatsoever , and the sound systems are good .',\n",
              " 'People began to make music specifically for discos and for those sound systems .',\n",
              " 'And , as with jazz , the dancers liked certain sections more than they did others .',\n",
              " 'So the early hip-hop guys would loop certain sections .',\n",
              " 'The MC would improvise lyrics in the same way that the jazz players would improvise melodies .',\n",
              " 'And another new form of music was born .',\n",
              " 'Live performance , when it was incredibly successful , ended up in what is probably , acoustically , the worst sounding venues on the planet : sports stadiums , basketball arenas and hockey arenas .',\n",
              " 'Musicians who ended up there did the best they could .',\n",
              " 'They wrote what is now called arena rock , which is medium-speed ballads .',\n",
              " 'They did the best they could given that this is what they &apos;re writing for .',\n",
              " 'The tempos are medium . It sounds big .',\n",
              " 'It &apos;s more a social situation than a musical situation .',\n",
              " 'And in some ways , the music that they &apos;re writing for this place works perfectly .',\n",
              " 'So there &apos;s more new venues .',\n",
              " 'One of the new ones is the automobile .',\n",
              " 'I grew up with a radio in a car .',\n",
              " 'But now that &apos;s evolved into something else .',\n",
              " 'The car is a whole venue .',\n",
              " 'The music that , I would say , is written for automobile sound systems works perfectly on it .',\n",
              " 'It might not be what you want to listen to at home , but it works great in the car -- has a huge frequency spectrum , you know , big bass and high-end and the voice kind of stuck in the middle .',\n",
              " 'Automobile music , you can share with your friends .',\n",
              " 'There &apos;s one other kind of new venue , the private MP3 player .',\n",
              " 'Presumably , this is just for Christian music .',\n",
              " 'And in some ways it &apos;s like Carnegie Hall , or when the audience had to hush up , because you can now hear every single detail .',\n",
              " 'In other ways , it &apos;s more like the West African music because if the music in an MP3 player gets too quiet , you turn it up , and the next minute , your ears are blasted out by a louder passage .',\n",
              " 'So that doesn &apos;t really work .',\n",
              " 'I think pop music , mainly , it &apos;s written today , to some extent , is written for these kind of players , for this kind of personal experience where you can hear extreme detail , but the dynamic doesn &apos;t change that much .',\n",
              " 'So I asked myself : Okay , is this a model for creation , this adaptation that we do ?',\n",
              " 'And does it happen anywhere else ?',\n",
              " 'Well , according to David Attenborough and some other people , birds do it too -- that the birds in the canopy , where the foliage is dense , their calls tend to be high-pitched , short and repetitive .',\n",
              " 'And the birds on the floor tend to have lower pitched calls , so that they don &apos;t get distorted when they bounce off the forest floor .',\n",
              " 'And birds like this Savannah sparrow , they tend to have a buzzing type call .',\n",
              " 'And it turns out that a sound like this is the most energy efficient and practical way to transmit their call across the fields and savannahs .',\n",
              " 'Other birds , like this tanager , have adapted within the same species .',\n",
              " 'The tananger on the East Coast of the United States , where the forests are a little denser , has one kind of call , and the tananger on the other side , on the west has a different kind of call .',\n",
              " 'So birds do it too .',\n",
              " 'And I thought : Well , if this is a model for creation , if we make music , primarily the form at least , to fit these contexts , and if we make art to fit gallery walls or museum walls , and if we write software to fit existing operating systems , is that how it works ?',\n",
              " 'Yeah . I think it &apos;s evolutionary .',\n",
              " 'It &apos;s adaptive .',\n",
              " 'But the pleasure and the passion and the joy is still there .',\n",
              " 'This is a reverse view of things from the kind of traditional Romantic view .',\n",
              " 'The Romantic view is that first comes the passion and then the outpouring of emotion , and then somehow it gets shaped into something .',\n",
              " 'And I &apos;m saying , well , the passion &apos;s still there , but the vessel that it &apos;s going to be injected into and poured into , that is instinctively and intuitively created first .',\n",
              " 'We already know where that passion is going .',\n",
              " 'But this conflict of views is kind of interesting .',\n",
              " 'The writer , Thomas Frank , says that this might be a kind of explanation why some voters vote against their best interests , that voters , like a lot of us , assume , that if they hear something that sounds like it &apos;s sincere , that it &apos;s coming from the gut , that it &apos;s passionate , that it &apos;s more authentic .',\n",
              " 'And they &apos;ll vote for that .',\n",
              " 'So that , if somebody can fake sincerity , if they can fake passion , they stand a better chance which seems a little dangerous .',\n",
              " 'I &apos;m saying the two , the passion , the joy , are not mutually exclusive .',\n",
              " 'Maybe what the world needs now is for us to realize that we are like the birds .',\n",
              " 'We adapt .',\n",
              " 'We sing .',\n",
              " 'And like the birds , the joy is still there , even though we have changed what we do to fit the context .',\n",
              " 'Thank you very much .',\n",
              " 'Kevin Breel : Confessions of a depressed comic',\n",
              " 'Kevin Breel didn &apos;t look like a depressed kid : team captain , at every party , funny and confident . But he tells the story of the night he realized that -- to save his own life -- he needed to say four simple words .',\n",
              " 'For a long time in my life , I felt like I &apos;d been living two different lives .',\n",
              " 'There &apos;s the life that everyone sees , and then there &apos;s the life that only I see .',\n",
              " 'And in the life that everyone sees , who I am is a friend , a son , a brother , a stand-up comedian and a teenager .',\n",
              " 'That &apos;s the life everyone sees .',\n",
              " 'If you were to ask my friends and family to describe me , that &apos;s what they would tell you .',\n",
              " 'And that &apos;s a huge part of me . That is who I am .',\n",
              " 'And if you were to ask me to describe myself , I &apos;d probably say some of those same things .',\n",
              " 'And I wouldn &apos;t be lying , but I wouldn &apos;t totally be telling you the truth , either , because the truth is , that &apos;s just the life everyone else sees .',\n",
              " 'In the life that only I see , who I am , who I really am , is someone who struggles intensely with depression .',\n",
              " 'I have for the last six years of my life , and I continue to every day .',\n",
              " 'Now , for someone who has never experienced depression or doesn &apos;t really know what that means , that might surprise them to hear , because there &apos;s this pretty popular misconception that depression is just being sad when something in your life goes wrong , when you break up with your girlfriend , when you lose a loved one , when you don &apos;t get the job you wanted .',\n",
              " 'But that &apos;s sadness . That &apos;s a natural thing .',\n",
              " 'That &apos;s a natural human emotion .',\n",
              " 'Real depression isn &apos;t being sad when something in your life goes wrong .',\n",
              " 'Real depression is being sad when everything in your life is going right .',\n",
              " 'That &apos;s real depression , and that &apos;s what I suffer from .',\n",
              " 'And to be totally honest , that &apos;s hard for me to stand up here and say .',\n",
              " 'It &apos;s hard for me to talk about , and it seems to be hard for everyone to talk about , so much so that no one &apos;s talking about it .',\n",
              " 'And no one &apos;s talking about depression , but we need to be , because right now it &apos;s a massive problem .',\n",
              " 'It &apos;s a massive problem .',\n",
              " 'But we don &apos;t see it on social media , right ?',\n",
              " 'We don &apos;t see it on Facebook . We don &apos;t see it on Twitter .',\n",
              " 'We don &apos;t see it on the news , because it &apos;s not happy , it &apos;s not fun , it &apos;s not light .',\n",
              " 'And so because we don &apos;t see it , we don &apos;t see the severity of it .',\n",
              " 'But the severity of it and the seriousness of it is this : every 30 seconds , every 30 seconds , somewhere , someone in the world takes their own life because of depression , and it might be two blocks away , it might be two countries away , it might be two continents away , but it &apos;s happening , and it &apos;s happening every single day .',\n",
              " 'And we have a tendency , as a society , to look at that and go , &quot; So what ? &quot;',\n",
              " 'So what ? We look at that , and we go , &quot; That &apos;s your problem .',\n",
              " 'That &apos;s their problem . &quot;',\n",
              " 'We say we &apos;re sad and we say we &apos;re sorry , but we also say , &quot; So what ? &quot;',\n",
              " 'Well , two years ago it was my problem , because I sat on the edge of my bed where I &apos;d sat a million times before and I was suicidal .',\n",
              " 'I was suicidal , and if you were to look at my life on the surface , you wouldn &apos;t see a kid who was suicidal .',\n",
              " 'You &apos;d see a kid who was the captain of his basketball team , the drama and theater student of the year , the English student of the year , someone who was consistently on the honor roll and consistently at every party .',\n",
              " 'So you would say I wasn &apos;t depressed , you would say I wasn &apos;t suicidal , but you would be wrong .',\n",
              " 'You would be wrong . So I sat there that night beside a bottle of pills with a pen and paper in my hand and I thought about taking my own life and I came this close to doing it .',\n",
              " 'I came this close to doing it .',\n",
              " 'And I didn &apos;t , so that makes me one of the lucky ones , one of the people who gets to step out on the ledge and look down but not jump , one of the lucky ones who survives .',\n",
              " 'Well , I survived , and that just leaves me with my story , and my story is this : In four simple words , I suffer from depression .',\n",
              " 'I suffer from depression , and for a long time , I think , I was living two totally different lives , where one person was always afraid of the other .',\n",
              " 'I was afraid that people would see me for who I really was , that I wasn &apos;t the perfect , popular kid in high school everyone thought I was , that beneath my smile , there was struggle , and beneath my light , there was dark , and beneath my big personality just hid even bigger pain .',\n",
              " 'See , some people might fear girls not liking them back .',\n",
              " 'Some people might fear sharks . Some people might fear death .',\n",
              " 'But for me , for a large part of my life , I feared myself .',\n",
              " 'I feared my truth , I feared my honesty , I feared my vulnerability , and that fear made me feel like I was forced into a corner , like I was forced into a corner and there was only one way out , and so I thought about that way every single day .',\n",
              " 'I thought about it every single day , and if I &apos;m being totally honest , standing here I &apos;ve thought about it again since , because that &apos;s the sickness , that &apos;s the struggle , that &apos;s depression , and depression isn &apos;t chicken pox .',\n",
              " 'You don &apos;t beat it once and it &apos;s gone forever .',\n",
              " 'It &apos;s something you live with . It &apos;s something you live in .',\n",
              " 'It &apos;s the roommate you can &apos;t kick out . It &apos;s the voice you can &apos;t ignore .',\n",
              " 'It &apos;s the feelings you can &apos;t seem to escape , the scariest part is that after a while , you become numb to it . It becomes normal for you , and what you really fear the most isn &apos;t the suffering inside of you .',\n",
              " 'It &apos;s the stigma inside of others , it &apos;s the shame , it &apos;s the embarrassment , it &apos;s the disapproving look on a friend &apos;s face , it &apos;s the whispers in the hallway that you &apos;re weak , it &apos;s the comments that you &apos;re crazy .',\n",
              " 'That &apos;s what keeps you from getting help .',\n",
              " 'That &apos;s what makes you hold it in and hide it .',\n",
              " 'It &apos;s the stigma . So you hold it in and you hide it , and you hold it in and you hide it , and even though it &apos;s keeping you in bed every day and it &apos;s making your life feel empty no matter how much you try and fill it , you hide it , because the stigma in our society around depression is very real .',\n",
              " 'It &apos;s very real , and if you think that it isn &apos;t , ask yourself this : Would you rather make your next Facebook status say you &apos;re having a tough time getting out of bed because you hurt your back or you &apos;re having a tough time getting out of bed every morning because you &apos;re depressed ?',\n",
              " 'That &apos;s the stigma , because unfortunately , we live in a world where if you break your arm , everyone runs over to sign your cast , but if you tell people you &apos;re depressed , everyone runs the other way .',\n",
              " 'That &apos;s the stigma .',\n",
              " 'We are so , so , so accepting of any body part breaking down other than our brains . And that &apos;s ignorance .',\n",
              " 'That &apos;s pure ignorance , and that ignorance has created a world that doesn &apos;t understand depression , that doesn &apos;t understand mental health .',\n",
              " 'And that &apos;s ironic to me , because depression is one of the best documented problems we have in the world , yet it &apos;s one of the least discussed .',\n",
              " 'We just push it aside and put it in a corner and pretend it &apos;s not there and hope it &apos;ll fix itself .',\n",
              " 'Well , it won &apos;t . It hasn &apos;t , and it &apos;s not going to , because that &apos;s wishful thinking , and wishful thinking isn &apos;t a game plan , it &apos;s procrastination , and we can &apos;t procrastinate on something this important .',\n",
              " 'The first step in solving any problem is recognizing there is one .',\n",
              " 'Well , we haven &apos;t done that , so we can &apos;t really expect to find an answer when we &apos;re still afraid of the question .',\n",
              " 'And I don &apos;t know what the solution is .',\n",
              " 'I wish I did , but I don &apos;t -- but I think , I think it has to start here .',\n",
              " 'It has to start with me , it has to start with you , it has to start with the people who are suffering , the ones who are hidden in the shadows .',\n",
              " 'We need to speak up and shatter the silence .',\n",
              " 'We need to be the ones who are brave for what we believe in , because if there &apos;s one thing that I &apos;ve come to realize , if there &apos;s one thing that I see as the biggest problem , it &apos;s not in building a world where we eliminate the ignorance of others .',\n",
              " 'It &apos;s in building a world where we teach the acceptance of ourselves , where we &apos;re okay with who we are , because when we get honest , we see that we all struggle and we all suffer .',\n",
              " 'Whether it &apos;s with this , whether it &apos;s with something else , we all know what it is to hurt .',\n",
              " 'We all know what it is to have pain in our heart , and we all know how important it is to heal .',\n",
              " 'But right now , depression is society &apos;s deep cut that we &apos;re content to put a Band-Aid over and pretend it &apos;s not there .',\n",
              " 'Well , it is there . It is there , and you know what ? It &apos;s okay .',\n",
              " 'Depression is okay . If you &apos;re going through it , know that you &apos;re okay .',\n",
              " 'And know that you &apos;re sick , you &apos;re not weak , and it &apos;s an issue , not an identity , because when you get past the fear and the ridicule and the judgment and the stigma of others , you can see depression for what it really is , and that &apos;s just a part of life , just a part of life , and as much as I hate , as much as I hate some of the places , some of the parts of my life depression has dragged me down to , in a lot of ways I &apos;m grateful for it .',\n",
              " 'Because yeah , it &apos;s put me in the valleys , but only to show me there &apos;s peaks , and yeah it &apos;s dragged me through the dark but only to remind me there is light .',\n",
              " 'My pain , more than anything in 19 years on this planet , has given me perspective , and my hurt , my hurt has forced me to have hope , have hope and to have faith , faith in myself , faith in others , faith that it can get better , that we can change this , that we can speak up and speak out and fight back against ignorance , fight back against intolerance , and more than anything , learn to love ourselves , learn to accept ourselves for who we are , the people we are , not the people the world wants us to be .',\n",
              " 'Because the world I believe in is one where embracing your light doesn &apos;t mean ignoring your dark .',\n",
              " 'The world I believe in is one where we &apos;re measured by our ability to overcome adversities , not avoid them .',\n",
              " 'The world I believe in is one where I can look someone in the eye and say , &quot; I &apos;m going through hell , &quot; and they can look back at me and go , &quot; Me too , &quot; and that &apos;s okay , and it &apos;s okay because depression is okay . We &apos;re people .',\n",
              " 'We &apos;re people , and we struggle and we suffer and we bleed and we cry , and if you think that true strength means never showing any weakness , then I &apos;m here to tell you you &apos;re wrong .',\n",
              " 'You &apos;re wrong , because it &apos;s the opposite .',\n",
              " 'We &apos;re people , and we have problems .',\n",
              " 'We &apos;re not perfect , and that &apos;s okay .',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCUMmetGy3IW"
      },
      "source": [
        "Embedding Layer with Position Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCAPf3boy0YR"
      },
      "source": [
        "class Embedder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.d_model = d_model\n",
        "        \n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.embed(x)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UUnfucwFVHV"
      },
      "source": [
        "The proposed author's method does not suffer from the limitations we have just mentioned. The positions of the words are encoded with a word embedding sized vector and added directly to the word embedding.\n",
        "\n",
        "![](https://pbcquoc.github.io/images/transformer/embedding.jpg)\n",
        "\n",
        "Specifically, at the even position, the author uses the sine function, and for the odd position uses the cos function to calculate the value in that dimension.\n",
        "![alt text](https://github.com/pbcquoc/pbcquoc.github.io/raw/master/images/transformer/pe_formula.png)\n",
        "\n",
        "In this picture below, I illustrate how to calculate position encoding . Assuming we have word embedding with 6 dimensions, then position encoding has 6 dimensions respectively. Each line corresponds to a word. The value of the vectors at each position is calculated according to the formula in the figure below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwA7eYk5y5ZQ"
      },
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_length=200, dropout=0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        pe = torch.zeros(max_seq_length, d_model)\n",
        "        \n",
        "       \n",
        "        for pos in range(max_seq_length):\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos, i] = math.sin(pos/(10000**(2*i/d_model)))\n",
        "                pe[pos, i+1] = math.cos(pos/(10000**((2*i+1)/d_model)))\n",
        "        pe = pe.unsqueeze(0)        \n",
        "        self.register_buffer('pe', pe)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = x*math.sqrt(self.d_model)\n",
        "        seq_length = x.size(1)\n",
        "        \n",
        "        pe = Variable(self.pe[:, :seq_length], requires_grad=False)\n",
        "        \n",
        "        if x.is_cuda:\n",
        "            pe.cuda()\n",
        "        # add embedding vector with pe\n",
        "        x = x + pe\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        return x\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCCICBhRzHiX"
      },
      "source": [
        "Multi Head Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvpIhvlZzBlf"
      },
      "source": [
        "def attention(q, k, v, mask=None, dropout=None):\n",
        "    \"\"\"\n",
        "    q: batch_size x head x seq_length x d_model\n",
        "    k: batch_size x head x seq_length x d_model\n",
        "    v: batch_size x head x seq_length x d_model\n",
        "    mask: batch_size x 1 x 1 x seq_length\n",
        "    output: batch_size x head x seq_length x d_model\n",
        "    \"\"\"\n",
        "\n",
        "    # # attention score is calculated by multiplying q by k\n",
        "    d_k = q.size(-1)\n",
        "    scores = torch.matmul(q, k.transpose(-2, -1))/math.sqrt(d_k)\n",
        "    \n",
        "    if mask is not None:\n",
        "        mask = mask.unsqueeze(1)\n",
        "        scores = scores.masked_fill(mask==0, -1e9)\n",
        "    # After that, normalize by softmax\n",
        "    scores = F.softmax(scores, dim=-1)\n",
        "    \n",
        "    if dropout is not None:\n",
        "        scores = dropout(scores)\n",
        "    \n",
        "    output = torch.matmul(scores, v)\n",
        "    return output, scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLi2DqQBzKBx"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, heads, d_model, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % heads == 0\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.d_k = d_model//heads\n",
        "        self.h = heads\n",
        "        self.attn = None\n",
        "\n",
        "        # create 3 weight matrices q_linear, k_linear, v_linear as shown above\n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "    \n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        \"\"\"\n",
        "        q: batch_size x seq_length x d_model\n",
        "        k: batch_size x seq_length x d_model\n",
        "        v: batch_size x seq_length x d_model\n",
        "        mask: batch_size x 1 x seq_length\n",
        "        output: batch_size x seq_length x d_model\n",
        "        \"\"\"\n",
        "        bs = q.size(0)\n",
        "       # multiply the weight matrix q_linear, k_linear, v_linear by the input data q, k, v\n",
        "        # in the encode step, you note that q, k, v is just one (see the picture above)\n",
        "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
        "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
        "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
        "        \n",
        "        q = q.transpose(1, 2)\n",
        "        k = k.transpose(1, 2)\n",
        "        v = v.transpose(1, 2)\n",
        "        \n",
        "        # # calculate attention score\n",
        "        scores, self.attn = attention(q, k, v, mask, self.dropout)\n",
        "        \n",
        "        concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n",
        "        \n",
        "        output = self.out(concat)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPyrFzGOzS2Y"
      },
      "source": [
        "Residuals Connection và Normalization Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PVPam-szQ-B"
      },
      "source": [
        "class Norm(nn.Module):\n",
        "    def __init__(self, d_model, eps = 1e-6):\n",
        "        super().__init__()\n",
        "    \n",
        "        self.size = d_model\n",
        "        \n",
        "        # create two learnable parameters to calibrate normalisation\n",
        "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
        "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
        "        \n",
        "        self.eps = eps\n",
        "    \n",
        "    def forward(self, x):\n",
        "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) \\\n",
        "        / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
        "        return norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibowy2YuzWiX"
      },
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \"\"\" Trong kiến trúc của chúng ta có tầng linear \n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, d_ff=2048, dropout = 0.1):\n",
        "        super().__init__() \n",
        "    \n",
        "        # We set d_ff as a default to 2048\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.dropout(F.relu(self.linear_1(x)))\n",
        "        x = self.linear_2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn4hvWyMzY3p"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.norm_1 = Norm(d_model)\n",
        "        self.norm_2 = Norm(d_model)\n",
        "        self.attn = MultiHeadAttention(heads, d_model, dropout=dropout)\n",
        "        self.ff = FeedForward(d_model, dropout=dropout)\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x, mask):\n",
        "        \"\"\"\n",
        "        x: batch_size x seq_length x d_model\n",
        "        mask: batch_size x 1 x seq_length\n",
        "        output: batch_size x seq_length x d_model\n",
        "        \"\"\"\n",
        "        \n",
        "        \n",
        "        x2 = self.norm_1(x)\n",
        "        # calculate attention value, you notice q, k, v are the same      \n",
        "        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n",
        "        x2 = self.norm_2(x)\n",
        "        x = x + self.dropout_2(self.ff(x2))\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5imffl7zb2i"
      },
      "source": [
        "**Decorder**\n",
        "\n",
        "Masked Multi Head Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdDQcfzYzeI_"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.norm_1 = Norm(d_model)\n",
        "        self.norm_2 = Norm(d_model)\n",
        "        self.norm_3 = Norm(d_model)\n",
        "        \n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "        self.dropout_3 = nn.Dropout(dropout)\n",
        "        \n",
        "        self.attn_1 = MultiHeadAttention(heads, d_model, dropout=dropout)\n",
        "        self.attn_2 = MultiHeadAttention(heads, d_model, dropout=dropout)\n",
        "        self.ff = FeedForward(d_model, dropout=dropout)\n",
        "\n",
        "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
        "        \"\"\"\n",
        "        x: batch_size x seq_length x d_model\n",
        "        e_outputs: batch_size x seq_length x d_model\n",
        "        src_mask: batch_size x 1 x seq_length\n",
        "        trg_mask: batch_size x 1 x seq_length\n",
        "        \"\"\"\n",
        "\n",
        "        x2 = self.norm_1(x)\n",
        "        # multihead attention first, notice the words in target\n",
        "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
        "        x2 = self.norm_2(x)\n",
        "       # masked mulithead 2nd attention. k, v is the output value of the encoder model\n",
        "        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs, src_mask))\n",
        "        x2 = self.norm_3(x)\n",
        "        x = x + self.dropout_3(self.ff(x2))\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSFb0lufbfux"
      },
      "source": [
        "**Encoder settings**\n",
        "\n",
        "including N encoder layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YocY9uAuzlWy"
      },
      "source": [
        "import copy\n",
        "\n",
        "def get_clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"Một encoder có nhiều encoder layer nhé !!!\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, d_model, N, heads, dropout):\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        self.embed = Embedder(vocab_size, d_model)\n",
        "        self.pe = PositionalEncoder(d_model, dropout=dropout)\n",
        "        self.layers = get_clones(EncoderLayer(d_model, heads, dropout), N)\n",
        "        self.norm = Norm(d_model)\n",
        "        \n",
        "    def forward(self, src, mask):\n",
        "        \"\"\"\n",
        "        src: batch_size x seq_length\n",
        "        mask: batch_size x 1 x seq_length\n",
        "        output: batch_size x seq_length x d_model\n",
        "        \"\"\"\n",
        "        x = self.embed(src)\n",
        "        x = self.pe(x)\n",
        "        for i in range(self.N):\n",
        "            x = self.layers[i](x, mask)\n",
        "        return self.norm(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9Pv02TDbqt7"
      },
      "source": [
        "**Install Decoder**\n",
        "\n",
        "Includes N decoder layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqCrXhc9zmch"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"Một decoder có nhiều decoder layer nhé !!!\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, d_model, N, heads, dropout):\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        self.embed = Embedder(vocab_size, d_model)\n",
        "        self.pe = PositionalEncoder(d_model, dropout=dropout)\n",
        "        self.layers = get_clones(DecoderLayer(d_model, heads, dropout), N)\n",
        "        self.norm = Norm(d_model)\n",
        "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
        "        \"\"\"\n",
        "        trg: batch_size x seq_length\n",
        "        e_outputs: batch_size x seq_length x d_model\n",
        "        src_mask: batch_size x 1 x seq_length\n",
        "        trg_mask: batch_size x 1 x seq_length\n",
        "        output: batch_size x seq_length x d_model\n",
        "        \"\"\"\n",
        "        x = self.embed(trg)\n",
        "        x = self.pe(x)\n",
        "        for i in range(self.N):\n",
        "            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n",
        "        return self.norm(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDdztAdMbxhu"
      },
      "source": [
        "**Install Transformers**\n",
        "\n",
        "including encoder and decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzNUbd5xzwF3"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    \"\"\" Cuối cùng ghép chúng lại với nhau để được mô hình transformer hoàn chỉnh\n",
        "    \"\"\"\n",
        "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads, dropout):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(src_vocab, d_model, N, heads, dropout)\n",
        "        self.decoder = Decoder(trg_vocab, d_model, N, heads, dropout)\n",
        "        self.out = nn.Linear(d_model, trg_vocab)\n",
        "    def forward(self, src, trg, src_mask, trg_mask):\n",
        "        \"\"\"\n",
        "        src: batch_size x seq_length\n",
        "        trg: batch_size x seq_length\n",
        "        src_mask: batch_size x 1 x seq_length\n",
        "        trg_mask batch_size x 1 x seq_length\n",
        "        output: batch_size x seq_length x vocab_size\n",
        "        \"\"\"\n",
        "        e_outputs = self.encoder(src, src_mask)\n",
        "        \n",
        "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
        "        output = self.out(d_output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2sCw1ysb7d5"
      },
      "source": [
        "We use torchtext to load data, which reduces time and efficiency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioXxelhoz3Oq"
      },
      "source": [
        "from torchtext import data\n",
        "\n",
        "class MyIterator(data.Iterator):\n",
        "    def create_batches(self):\n",
        "        if self.train:\n",
        "            def pool(d, random_shuffler):\n",
        "                for p in data.batch(d, self.batch_size * 100):\n",
        "                    p_batch = data.batch(\n",
        "                        sorted(p, key=self.sort_key),\n",
        "                        self.batch_size, self.batch_size_fn)\n",
        "                    for b in random_shuffler(list(p_batch)):\n",
        "                        yield b\n",
        "            self.batches = pool(self.data(), self.random_shuffler)\n",
        "            \n",
        "        else:\n",
        "            self.batches = []\n",
        "            for b in data.batch(self.data(), self.batch_size,\n",
        "                                          self.batch_size_fn):\n",
        "                self.batches.append(sorted(b, key=self.sort_key))\n",
        "\n",
        "global max_src_in_batch, max_tgt_in_batch\n",
        "\n",
        "def batch_size_fn(new, count, sofar):\n",
        "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
        "    global max_src_in_batch, max_tgt_in_batch\n",
        "    if count == 1:\n",
        "        max_src_in_batch = 0\n",
        "        max_tgt_in_batch = 0\n",
        "    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n",
        "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n",
        "    src_elements = count * max_src_in_batch\n",
        "    tgt_elements = count * max_tgt_in_batch\n",
        "    return max(src_elements, tgt_elements)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYVz3v1Kz6-H"
      },
      "source": [
        "def nopeak_mask(size, device):\n",
        "    \"\"\"Create a mask to be used in the decoder to predict during training\n",
        "     the model can't see the words in the future\n",
        "    \"\"\"\n",
        "    np_mask = np.triu(np.ones((1, size, size)),\n",
        "    k=1).astype('uint8')\n",
        "    np_mask =  Variable(torch.from_numpy(np_mask) == 0)\n",
        "    np_mask = np_mask.to(device)\n",
        "    \n",
        "    return np_mask\n",
        "\n",
        "def create_masks(src, trg, src_pad, trg_pad, device):\n",
        "    \"\"\" Create mask for encoder,\n",
        "    so that the model does not ignore the information of the PAD characters we added\n",
        "    \"\"\"\n",
        "    src_mask = (src != src_pad).unsqueeze(-2)\n",
        "\n",
        "    if trg is not None:\n",
        "        trg_mask = (trg != trg_pad).unsqueeze(-2)\n",
        "        size = trg.size(1) # get seq_len for matrix\n",
        "        np_mask = nopeak_mask(size, device)\n",
        "        if trg.is_cuda:\n",
        "            np_mask.cuda()\n",
        "        trg_mask = trg_mask & np_mask\n",
        "        \n",
        "    else:\n",
        "        trg_mask = None\n",
        "    return src_mask, trg_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYqWC0wqz964"
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "import re\n",
        "\n",
        "def get_synonym(word, SRC):\n",
        "    syns = wordnet.synsets(word)\n",
        "    for s in syns:\n",
        "        for l in s.lemmas():\n",
        "            if SRC.vocab.stoi[l.name()] != 0:\n",
        "                return SRC.vocab.stoi[l.name()]\n",
        "            \n",
        "    return 0\n",
        "\n",
        "def multiple_replace(dict, text):\n",
        "  # Create a regular expression  from the dictionary keys\n",
        "  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n",
        "\n",
        "  # For each match, look-up corresponding value in dictionary\n",
        "  return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeMUZktX0As5"
      },
      "source": [
        "def init_vars(src, model, SRC, TRG, device, k, max_len):\n",
        "    \"\"\" Calculate the required matrices during translation after the model is finished learning\n",
        "    \"\"\"\n",
        "    init_tok = TRG.vocab.stoi['<sos>']\n",
        "    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n",
        "\n",
        "    # encoder output available\n",
        "    e_output = model.encoder(src, src_mask)\n",
        "    \n",
        "    outputs = torch.LongTensor([[init_tok]])\n",
        "    \n",
        "    outputs = outputs.to(device)\n",
        "    \n",
        "    trg_mask = nopeak_mask(1, device)\n",
        "    # guess the first character\n",
        "    out = model.out(model.decoder(outputs,\n",
        "    e_output, src_mask, trg_mask))\n",
        "    out = F.softmax(out, dim=-1)\n",
        "    \n",
        "    probs, ix = out[:, -1].data.topk(k)\n",
        "    log_scores = torch.Tensor([math.log(prob) for prob in probs.data[0]]).unsqueeze(0)\n",
        "    \n",
        "    outputs = torch.zeros(k, max_len).long()\n",
        "    outputs = outputs.to(device)\n",
        "    outputs[:, 0] = init_tok\n",
        "    outputs[:, 1] = ix[0]\n",
        "    \n",
        "    e_outputs = torch.zeros(k, e_output.size(-2),e_output.size(-1))\n",
        "   \n",
        "    e_outputs = e_outputs.to(device)\n",
        "    e_outputs[:, :] = e_output[0]\n",
        "    \n",
        "    return outputs, e_outputs, log_scores\n",
        "\n",
        "def k_best_outputs(outputs, out, log_scores, i, k):\n",
        "    \n",
        "    probs, ix = out[:, -1].data.topk(k)\n",
        "    log_probs = torch.Tensor([math.log(p) for p in probs.data.view(-1)]).view(k, -1) + log_scores.transpose(0,1)\n",
        "    k_probs, k_ix = log_probs.view(-1).topk(k)\n",
        "    \n",
        "    row = k_ix // k\n",
        "    col = k_ix % k\n",
        "\n",
        "    outputs[:, :i] = outputs[row, :i]\n",
        "    outputs[:, i] = ix[row, col]\n",
        "\n",
        "    log_scores = k_probs.unsqueeze(0)\n",
        "    \n",
        "    return outputs, log_scores\n",
        "\n",
        "def beam_search(src, model, SRC, TRG, device, k, max_len):    \n",
        "\n",
        "    outputs, e_outputs, log_scores = init_vars(src, model, SRC, TRG, device, k, max_len)\n",
        "    eos_tok = TRG.vocab.stoi['<eos>']\n",
        "    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n",
        "    ind = None\n",
        "    for i in range(2, max_len):\n",
        "    \n",
        "        trg_mask = nopeak_mask(i, device)\n",
        "\n",
        "        out = model.out(model.decoder(outputs[:,:i],\n",
        "        e_outputs, src_mask, trg_mask))\n",
        "\n",
        "        out = F.softmax(out, dim=-1)\n",
        "    \n",
        "        outputs, log_scores = k_best_outputs(outputs, out, log_scores, i, k)\n",
        "        \n",
        "        ones = (outputs==eos_tok).nonzero() # Occurrences of end symbols for all input sentences.\n",
        "        sentence_lengths = torch.zeros(len(outputs), dtype=torch.long).cuda()\n",
        "        for vec in ones:\n",
        "            i = vec[0]\n",
        "            if sentence_lengths[i]==0: # First end symbol has not been found yet\n",
        "                sentence_lengths[i] = vec[1] # Position of first end symbol\n",
        "\n",
        "        num_finished_sentences = len([s for s in sentence_lengths if s > 0])\n",
        "\n",
        "        if num_finished_sentences == k:\n",
        "            alpha = 0.7\n",
        "            div = 1/(sentence_lengths.type_as(log_scores)**alpha)\n",
        "            _, ind = torch.max(log_scores * div, 1)\n",
        "            ind = ind.data[0]\n",
        "            break\n",
        "    \n",
        "    if ind is None:\n",
        "        \n",
        "        length = (outputs[0]==eos_tok).nonzero()[0] if len((outputs[0]==eos_tok).nonzero()) > 0 else -1\n",
        "        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[0][1:length]])\n",
        "    \n",
        "    else:\n",
        "        length = (outputs[ind]==eos_tok).nonzero()[0]\n",
        "        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[ind][1:length]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBZSNzWm0EeJ"
      },
      "source": [
        "def translate_sentence(sentence, model, SRC, TRG, device, k, max_len):\n",
        "    \"\"\"Translate a sentence using beamsearch\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    indexed = []\n",
        "    sentence = SRC.preprocess(sentence)\n",
        "    \n",
        "    for tok in sentence:\n",
        "        if SRC.vocab.stoi[tok] != SRC.vocab.stoi['<eos>']:\n",
        "            indexed.append(SRC.vocab.stoi[tok])\n",
        "        else:\n",
        "            indexed.append(get_synonym(tok, SRC))\n",
        "    \n",
        "    sentence = Variable(torch.LongTensor([indexed]))\n",
        "    \n",
        "    sentence = sentence.to(device)\n",
        "    \n",
        "    sentence = beam_search(sentence, model, SRC, TRG, device, k, max_len)\n",
        "\n",
        "    return  multiple_replace({' ?' : '?',' !':'!',' .':'.','\\' ':'\\'',' ,':','}, sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ32SPnG0HA_"
      },
      "source": [
        "import spacy\n",
        "import re\n",
        "\n",
        "class tokenize(object):\n",
        "    \n",
        "    def __init__(self, lang):\n",
        "        self.nlp = spacy.load(lang)\n",
        "            \n",
        "    def tokenizer(self, sentence):\n",
        "        sentence = re.sub(\n",
        "        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(sentence))\n",
        "        sentence = re.sub(r\"[ ]+\", \" \", sentence)\n",
        "        sentence = re.sub(r\"\\!+\", \"!\", sentence)\n",
        "        sentence = re.sub(r\"\\,+\", \",\", sentence)\n",
        "        sentence = re.sub(r\"\\?+\", \"?\", sentence)\n",
        "        sentence = sentence.lower()\n",
        "        return [tok.text for tok in self.nlp.tokenizer(sentence) if tok.text != \" \"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9Ww-eeN0RCO"
      },
      "source": [
        "**Data loader**\n",
        "\n",
        "Use torchtext to load data quickly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWnPTuSV0LP5"
      },
      "source": [
        "import os\n",
        "import dill as pickle\n",
        "import pandas as pd\n",
        "\n",
        "def create_fields(src_lang, trg_lang):\n",
        "    \n",
        "    print(\"loading spacy tokenizers...\")\n",
        "    \n",
        "    t_src = tokenize(src_lang)\n",
        "    t_trg = tokenize(trg_lang)\n",
        "\n",
        "    TRG = data.Field(lower=True, tokenize=t_trg.tokenizer, init_token='<sos>', eos_token='<eos>')\n",
        "    SRC = data.Field(lower=True, tokenize=t_src.tokenizer)\n",
        "        \n",
        "    return SRC, TRG\n",
        "\n",
        "def create_dataset(src_data, trg_data, max_strlen, batchsize, device, SRC, TRG, istrain=True):\n",
        "\n",
        "    print(\"creating dataset and iterator... \")\n",
        "\n",
        "    raw_data = {'src' : [line for line in src_data], 'trg': [line for line in trg_data]}\n",
        "    df = pd.DataFrame(raw_data, columns=[\"src\", \"trg\"])\n",
        "    \n",
        "    mask = (df['src'].str.count(' ') < max_strlen) & (df['trg'].str.count(' ') < max_strlen)\n",
        "    df = df.loc[mask]\n",
        "\n",
        "    df.to_csv(\"translate_transformer_temp.csv\", index=False)\n",
        "    \n",
        "    data_fields = [('src', SRC), ('trg', TRG)]\n",
        "    train = data.TabularDataset('./translate_transformer_temp.csv', format='csv', fields=data_fields)\n",
        "\n",
        "    train_iter = MyIterator(train, batch_size=batchsize, device=device,\n",
        "                        repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
        "                        batch_size_fn=batch_size_fn, train=istrain, shuffle=True)\n",
        "    \n",
        "    os.remove('translate_transformer_temp.csv')\n",
        "    \n",
        "    if istrain:\n",
        "        SRC.build_vocab(train)\n",
        "        TRG.build_vocab(train)\n",
        "\n",
        "    return train_iter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz-_Yo1d0Vmb"
      },
      "source": [
        "def step(model, optimizer,batch, criterion):\n",
        "    \"\"\"\n",
        "    Một lần cập nhật mô hình\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    \n",
        "    src = batch.src.transpose(0,1).cuda()\n",
        "    trg = batch.trg.transpose(0,1).cuda()\n",
        "    trg_input = trg[:, :-1]\n",
        "    src_mask, trg_mask = create_masks(src, trg_input, src_pad, trg_pad, opt['device'])\n",
        "    preds = model(src, trg_input, src_mask, trg_mask)\n",
        "\n",
        "    ys = trg[:, 1:].contiguous().view(-1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(preds.view(-1, preds.size(-1)), ys)\n",
        "    loss.backward()\n",
        "    optimizer.step_and_update_lr()\n",
        "    \n",
        "    loss = loss.item()\n",
        "    \n",
        "    return loss    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baYrC56O0Y-u"
      },
      "source": [
        "def validiate(model, valid_iter, criterion):\n",
        "    \"\"\" Tính loss trên tập validation\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        total_loss = []\n",
        "        for batch in valid_iter:\n",
        "            src = batch.src.transpose(0,1).cuda()\n",
        "            trg = batch.trg.transpose(0,1).cuda()\n",
        "            trg_input = trg[:, :-1]\n",
        "            src_mask, trg_mask = create_masks(src, trg_input, src_pad, trg_pad, opt['device'])\n",
        "            preds = model(src, trg_input, src_mask, trg_mask)\n",
        "\n",
        "            ys = trg[:, 1:].contiguous().view(-1)\n",
        "            \n",
        "            loss = criterion(preds.view(-1, preds.size(-1)), ys)\n",
        "            \n",
        "            loss = loss.item()\n",
        "            \n",
        "            total_loss.append(loss)\n",
        "        \n",
        "    avg_loss = np.mean(total_loss)\n",
        "    \n",
        "    return avg_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pTISv4lcNFv"
      },
      "source": [
        "**Optimizer**\n",
        "\n",
        "To train the transformer model, you still use Adam, however, the learning rate needs to be adjusted during the learning process according to the following formula"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnt9brDT0jNK"
      },
      "source": [
        "class ScheduledOptim():\n",
        "    '''A simple wrapper class for learning rate scheduling'''\n",
        "\n",
        "    def __init__(self, optimizer, init_lr, d_model, n_warmup_steps):\n",
        "        self._optimizer = optimizer\n",
        "        self.init_lr = init_lr\n",
        "        self.d_model = d_model\n",
        "        self.n_warmup_steps = n_warmup_steps\n",
        "        self.n_steps = 0\n",
        "\n",
        "\n",
        "    def step_and_update_lr(self):\n",
        "        \"Step with the inner optimizer\"\n",
        "        self._update_learning_rate()\n",
        "        self._optimizer.step()\n",
        "\n",
        "\n",
        "    def zero_grad(self):\n",
        "        \"Zero out the gradients with the inner optimizer\"\n",
        "        self._optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    def _get_lr_scale(self):\n",
        "        d_model = self.d_model\n",
        "        n_steps, n_warmup_steps = self.n_steps, self.n_warmup_steps\n",
        "        return (d_model ** -0.5) * min(n_steps ** (-0.5), n_steps * n_warmup_steps ** (-1.5))\n",
        "\n",
        "    def state_dict(self):\n",
        "        optimizer_state_dict = {\n",
        "            'init_lr':self.init_lr,\n",
        "            'd_model':self.d_model,\n",
        "            'n_warmup_steps':self.n_warmup_steps,\n",
        "            'n_steps':self.n_steps,\n",
        "            '_optimizer':self._optimizer.state_dict(),\n",
        "        }\n",
        "        \n",
        "        return optimizer_state_dict\n",
        "    \n",
        "    def load_state_dict(self, state_dict):\n",
        "        self.init_lr = state_dict['init_lr']\n",
        "        self.d_model = state_dict['d_model']\n",
        "        self.n_warmup_steps = state_dict['n_warmup_steps']\n",
        "        self.n_steps = state_dict['n_steps']\n",
        "        \n",
        "        self._optimizer.load_state_dict(state_dict['_optimizer'])\n",
        "        \n",
        "    def _update_learning_rate(self):\n",
        "        ''' Learning rate scheduling per step '''\n",
        "\n",
        "        self.n_steps += 1\n",
        "        lr = self.init_lr * self._get_lr_scale()\n",
        "\n",
        "        for param_group in self._optimizer.param_groups:\n",
        "            param_group['lr'] = lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXP3aDJGcTI6"
      },
      "source": [
        "**Label** **Smoothing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7F-b7Rf0kDr"
      },
      "source": [
        "class LabelSmoothingLoss(nn.Module):\n",
        "    def __init__(self, classes, padding_idx, smoothing=0.0, dim=-1):\n",
        "        super(LabelSmoothingLoss, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.cls = classes\n",
        "        self.dim = dim\n",
        "        self.padding_idx = padding_idx\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = pred.log_softmax(dim=self.dim)\n",
        "        with torch.no_grad():\n",
        "            # true_dist = pred.data.clone()\n",
        "            true_dist = torch.zeros_like(pred)\n",
        "            true_dist.fill_(self.smoothing / (self.cls - 2))\n",
        "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "            true_dist[:, self.padding_idx] = 0\n",
        "            mask = torch.nonzero(target.data == self.padding_idx, as_tuple=False)\n",
        "            if mask.dim() > 0:\n",
        "                true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
        "            \n",
        "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO5IdwO80m-4"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def bleu(valid_src_data, valid_trg_data, model, SRC, TRG, device, k, max_strlen):\n",
        "    pred_sents = []\n",
        "    for sentence in valid_src_data:\n",
        "        pred_trg = translate_sentence(sentence, model, SRC, TRG, device, k, max_strlen)\n",
        "        pred_sents.append(pred_trg)\n",
        "    \n",
        "    pred_sents = [TRG.preprocess(sent) for sent in pred_sents]\n",
        "    trg_sents = [[sent.split()] for sent in valid_trg_data]\n",
        "    \n",
        "    return bleu_score(pred_sents, trg_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93xQ1iAc0qGM"
      },
      "source": [
        "opt = {\n",
        "    'train_src_data':'./data/train.en',\n",
        "    'train_trg_data':'./data/train.vi',\n",
        "    'valid_src_data':'./data/tst2013.en',\n",
        "    'valid_trg_data':'./data/tst2013.vi',\n",
        "    'src_lang':'en',\n",
        "    'trg_lang':'en',#'vi_spacy_model',\n",
        "    'max_strlen':160,\n",
        "    'batchsize':1500,\n",
        "    'device':'cuda',\n",
        "    'd_model': 512,\n",
        "    'n_layers': 6,\n",
        "    'heads': 8,\n",
        "    'dropout': 0.1,\n",
        "    'lr':0.0001,\n",
        "    'epochs':30,\n",
        "    'printevery': 200,\n",
        "    'k':5,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EedTN6ls5Srd",
        "outputId": "b55e5621-187d-4c61-8cda-d205d6375254"
      },
      "source": [
        "SRC, TRG = create_fields(opt['src_lang'], opt['trg_lang'])\n",
        "train_iter = create_dataset(train_src_data, train_trg_data, opt['max_strlen'], opt['batchsize'], opt['device'], SRC, TRG, istrain=True)\n",
        "valid_iter = create_dataset(valid_src_data, valid_trg_data, opt['max_strlen'], opt['batchsize'], opt['device'], SRC, TRG, istrain=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading spacy tokenizers...\n",
            "creating dataset and iterator... \n",
            "creating dataset and iterator... \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VINTME2K5ari"
      },
      "source": [
        "src_pad = SRC.vocab.stoi['<pad>']\n",
        "trg_pad = TRG.vocab.stoi['<pad>']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKwDlMzn5coG"
      },
      "source": [
        "model = Transformer(len(SRC.vocab), len(TRG.vocab), opt['d_model'], opt['n_layers'], opt['heads'], opt['dropout'])\n",
        "\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "model = model.to(opt['device'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnP82AsD5kM6"
      },
      "source": [
        "optimizer = ScheduledOptim(\n",
        "        torch.optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-09),\n",
        "        0.2, opt['d_model'], 4000)\n",
        "\n",
        "criterion = LabelSmoothingLoss(len(TRG.vocab), padding_idx=trg_pad, smoothing=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKNgIifIdOhi"
      },
      "source": [
        "Trian and evaluation on the test set based on the bleu "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RpJSGwAY5mck",
        "outputId": "a27efc1f-7386-44fd-cac0-004b1b38ed78"
      },
      "source": [
        "import time\n",
        "\n",
        "for epoch in range(opt['epochs']):\n",
        "    total_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(train_iter): \n",
        "        s = time.time()\n",
        "        loss = step(model, optimizer, batch, criterion)\n",
        "        \n",
        "        total_loss += loss\n",
        "        \n",
        "        if (i + 1) % opt['printevery'] == 0:\n",
        "            avg_loss = total_loss/opt['printevery']\n",
        "            print('epoch: {:03d} - iter: {:05d} - train loss: {:.4f} - time: {:.4f}'.format(epoch, i, avg_loss, time.time()- s))\n",
        "            total_loss = 0\n",
        "\n",
        "    s = time.time()\n",
        "    valid_loss = validiate(model, valid_iter, criterion)\n",
        "    bleuscore = bleu(valid_src_data[:500], valid_trg_data[:500], model, SRC, TRG, opt['device'], opt['k'], opt['max_strlen'])\n",
        "    print('epoch: {:03d} - iter: {:05d} - valid loss: {:.4f} - bleu score: {:.4f} - time: {:.4f}'.format(epoch, i, valid_loss, bleuscore, time.time() - s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 000 - iter: 00199 - train loss: 9.3141 - time: 0.1900\n",
            "epoch: 000 - iter: 00399 - train loss: 8.4590 - time: 0.2009\n",
            "epoch: 000 - iter: 00599 - train loss: 7.1945 - time: 0.2148\n",
            "epoch: 000 - iter: 00799 - train loss: 6.4858 - time: 0.2146\n",
            "epoch: 000 - iter: 00999 - train loss: 6.4343 - time: 0.2064\n",
            "epoch: 000 - iter: 01199 - train loss: 6.2971 - time: 0.2087\n",
            "epoch: 000 - iter: 01399 - train loss: 6.1013 - time: 0.2015\n",
            "epoch: 000 - iter: 01599 - train loss: 5.8779 - time: 0.2085\n",
            "epoch: 000 - iter: 01799 - train loss: 5.7458 - time: 0.2124\n",
            "epoch: 000 - iter: 01999 - train loss: 5.5707 - time: 0.2128\n",
            "epoch: 000 - iter: 02199 - train loss: 5.5048 - time: 0.1929\n",
            "epoch: 000 - iter: 02399 - train loss: 5.3976 - time: 0.2126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 000 - iter: 02497 - valid loss: 3.9697 - bleu score: 0.0127 - time: 138.2300\n",
            "epoch: 001 - iter: 00199 - train loss: 5.2078 - time: 0.2070\n",
            "epoch: 001 - iter: 00399 - train loss: 5.1739 - time: 0.2039\n",
            "epoch: 001 - iter: 00599 - train loss: 5.0552 - time: 0.2057\n",
            "epoch: 001 - iter: 00799 - train loss: 4.8281 - time: 0.2003\n",
            "epoch: 001 - iter: 00999 - train loss: 4.8805 - time: 0.2186\n",
            "epoch: 001 - iter: 01199 - train loss: 4.7690 - time: 0.2043\n",
            "epoch: 001 - iter: 01399 - train loss: 4.6824 - time: 0.2026\n",
            "epoch: 001 - iter: 01599 - train loss: 4.6193 - time: 0.2198\n",
            "epoch: 001 - iter: 01799 - train loss: 4.5520 - time: 0.2008\n",
            "epoch: 001 - iter: 01999 - train loss: 4.5005 - time: 0.1909\n",
            "epoch: 001 - iter: 02199 - train loss: 4.3856 - time: 0.1975\n",
            "epoch: 001 - iter: 02399 - train loss: 4.3173 - time: 0.1976\n",
            "epoch: 001 - iter: 02497 - valid loss: 3.1581 - bleu score: 0.1112 - time: 165.0388\n",
            "epoch: 002 - iter: 00199 - train loss: 4.2011 - time: 0.2077\n",
            "epoch: 002 - iter: 00399 - train loss: 4.1463 - time: 0.1960\n",
            "epoch: 002 - iter: 00599 - train loss: 4.0987 - time: 0.2116\n",
            "epoch: 002 - iter: 00799 - train loss: 4.0687 - time: 0.1979\n",
            "epoch: 002 - iter: 00999 - train loss: 3.9827 - time: 0.2102\n",
            "epoch: 002 - iter: 01199 - train loss: 4.0057 - time: 0.2052\n",
            "epoch: 002 - iter: 01399 - train loss: 3.9346 - time: 0.1953\n",
            "epoch: 002 - iter: 01599 - train loss: 3.8950 - time: 0.1884\n",
            "epoch: 002 - iter: 01799 - train loss: 3.8691 - time: 0.2070\n",
            "epoch: 002 - iter: 01999 - train loss: 3.8540 - time: 0.1966\n",
            "epoch: 002 - iter: 02199 - train loss: 3.8372 - time: 0.2066\n",
            "epoch: 002 - iter: 02399 - train loss: 3.7525 - time: 0.2250\n",
            "epoch: 002 - iter: 02497 - valid loss: 2.7808 - bleu score: 0.1791 - time: 167.8549\n",
            "epoch: 003 - iter: 00199 - train loss: 3.6854 - time: 0.2071\n",
            "epoch: 003 - iter: 00399 - train loss: 3.6375 - time: 0.1954\n",
            "epoch: 003 - iter: 00599 - train loss: 3.6068 - time: 0.2009\n",
            "epoch: 003 - iter: 00799 - train loss: 3.6328 - time: 0.2024\n",
            "epoch: 003 - iter: 00999 - train loss: 3.5865 - time: 0.2039\n",
            "epoch: 003 - iter: 01199 - train loss: 3.5983 - time: 0.2059\n",
            "epoch: 003 - iter: 01399 - train loss: 3.5421 - time: 0.1951\n",
            "epoch: 003 - iter: 01599 - train loss: 3.5627 - time: 0.1899\n",
            "epoch: 003 - iter: 01799 - train loss: 3.5449 - time: 0.2083\n",
            "epoch: 003 - iter: 01999 - train loss: 3.5258 - time: 0.2034\n",
            "epoch: 003 - iter: 02199 - train loss: 3.5183 - time: 0.2041\n",
            "epoch: 003 - iter: 02399 - train loss: 3.4522 - time: 0.1977\n",
            "epoch: 003 - iter: 02497 - valid loss: 2.6219 - bleu score: 0.1997 - time: 164.9975\n",
            "epoch: 004 - iter: 00199 - train loss: 3.3948 - time: 0.2157\n",
            "epoch: 004 - iter: 00399 - train loss: 3.3940 - time: 0.2002\n",
            "epoch: 004 - iter: 00599 - train loss: 3.3928 - time: 0.2140\n",
            "epoch: 004 - iter: 00799 - train loss: 3.3927 - time: 0.2083\n",
            "epoch: 004 - iter: 00999 - train loss: 3.3656 - time: 0.2051\n",
            "epoch: 004 - iter: 01199 - train loss: 3.3260 - time: 0.1951\n",
            "epoch: 004 - iter: 01399 - train loss: 3.3388 - time: 0.1851\n",
            "epoch: 004 - iter: 01599 - train loss: 3.3394 - time: 0.2221\n",
            "epoch: 004 - iter: 01799 - train loss: 3.3403 - time: 0.2148\n",
            "epoch: 004 - iter: 01999 - train loss: 3.3267 - time: 0.2065\n",
            "epoch: 004 - iter: 02199 - train loss: 3.3387 - time: 0.1989\n",
            "epoch: 004 - iter: 02399 - train loss: 3.3025 - time: 0.1900\n",
            "epoch: 004 - iter: 02497 - valid loss: 2.5283 - bleu score: 0.2233 - time: 177.8325\n",
            "epoch: 005 - iter: 00199 - train loss: 3.2270 - time: 0.2041\n",
            "epoch: 005 - iter: 00399 - train loss: 3.2140 - time: 0.1970\n",
            "epoch: 005 - iter: 00599 - train loss: 3.1709 - time: 0.2023\n",
            "epoch: 005 - iter: 00799 - train loss: 3.2161 - time: 0.2003\n",
            "epoch: 005 - iter: 00999 - train loss: 3.2243 - time: 0.1992\n",
            "epoch: 005 - iter: 01199 - train loss: 3.2125 - time: 0.1926\n",
            "epoch: 005 - iter: 01399 - train loss: 3.2218 - time: 0.2227\n",
            "epoch: 005 - iter: 01599 - train loss: 3.1821 - time: 0.1949\n",
            "epoch: 005 - iter: 01799 - train loss: 3.2086 - time: 0.2012\n",
            "epoch: 005 - iter: 01999 - train loss: 3.2323 - time: 0.2086\n",
            "epoch: 005 - iter: 02199 - train loss: 3.2162 - time: 0.2147\n",
            "epoch: 005 - iter: 02399 - train loss: 3.2132 - time: 0.2010\n",
            "epoch: 005 - iter: 02497 - valid loss: 2.4732 - bleu score: 0.2273 - time: 198.3034\n",
            "epoch: 006 - iter: 00199 - train loss: 3.1214 - time: 0.2057\n",
            "epoch: 006 - iter: 00399 - train loss: 3.1059 - time: 0.2044\n",
            "epoch: 006 - iter: 00599 - train loss: 3.0853 - time: 0.2047\n",
            "epoch: 006 - iter: 00799 - train loss: 3.1255 - time: 0.2121\n",
            "epoch: 006 - iter: 00999 - train loss: 3.1017 - time: 0.2011\n",
            "epoch: 006 - iter: 01199 - train loss: 3.1226 - time: 0.2119\n",
            "epoch: 006 - iter: 01399 - train loss: 3.1066 - time: 0.2025\n",
            "epoch: 006 - iter: 01599 - train loss: 3.1275 - time: 0.2094\n",
            "epoch: 006 - iter: 01799 - train loss: 3.1261 - time: 0.1915\n",
            "epoch: 006 - iter: 01999 - train loss: 3.1028 - time: 0.2060\n",
            "epoch: 006 - iter: 02199 - train loss: 3.0688 - time: 0.2048\n",
            "epoch: 006 - iter: 02399 - train loss: 3.0943 - time: 0.1789\n",
            "epoch: 006 - iter: 02497 - valid loss: 2.4279 - bleu score: 0.2398 - time: 196.8966\n",
            "epoch: 007 - iter: 00199 - train loss: 2.9983 - time: 0.1805\n",
            "epoch: 007 - iter: 00399 - train loss: 3.0200 - time: 0.2112\n",
            "epoch: 007 - iter: 00599 - train loss: 2.9956 - time: 0.2011\n",
            "epoch: 007 - iter: 00799 - train loss: 3.0077 - time: 0.2156\n",
            "epoch: 007 - iter: 00999 - train loss: 3.0359 - time: 0.1924\n",
            "epoch: 007 - iter: 01199 - train loss: 3.0263 - time: 0.2029\n",
            "epoch: 007 - iter: 01399 - train loss: 3.0532 - time: 0.1997\n",
            "epoch: 007 - iter: 01599 - train loss: 3.0175 - time: 0.2187\n",
            "epoch: 007 - iter: 01799 - train loss: 3.0501 - time: 0.1960\n",
            "epoch: 007 - iter: 01999 - train loss: 3.0158 - time: 0.2058\n",
            "epoch: 007 - iter: 02199 - train loss: 3.0250 - time: 0.1927\n",
            "epoch: 007 - iter: 02399 - train loss: 3.0235 - time: 0.1969\n",
            "epoch: 007 - iter: 02497 - valid loss: 2.4088 - bleu score: 0.2448 - time: 198.4330\n",
            "epoch: 008 - iter: 00199 - train loss: 2.9569 - time: 0.2159\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-f6e0011e0dc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-8e2ff4fecd01>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(model, optimizer, batch, criterion)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_and_update_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}